{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T02:28:14.461554Z",
     "start_time": "2025-07-29T02:24:01.140890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from tqdm import tqdm\n",
    "from utils import vggish_input, params\n",
    "from typing import Tuple, List\n",
    "\n",
    "# CONFIGURATION\n",
    "DATA_ROOT = Path(\"../Data/Experiment_Data\")\n",
    "RAW_DIR = DATA_ROOT / \"1_RawDataset\"\n",
    "SAVE_DIR = DATA_ROOT / \"3_PreprocessDataset_Oversample\"\n",
    "CLASS_LIST = ['Tooth_brushing', 'Washing_hands', 'Shower', 'Wiping', 'Vacuum_Cleaner', 'Other']\n",
    "OVERSAMPLE_FACTORS = {\n",
    "    '202': {'Tooth_brushing': 1.4, 'Washing_hands': 2.4, 'Wiping': 2.7},\n",
    "    '206': {'Tooth_brushing': 2.5},\n",
    "    '209': {'Washing_hands': 1.5},\n",
    "}\n",
    "\n",
    "# UTILITY FUNCTIONS\n",
    "def add_time_zero_row(df: pd.DataFrame, time_col='Time', unixtime_col='UnixTime') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure a row with elapsed time zero exists; if missing, insert one.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors='coerce')\n",
    "    df[unixtime_col] = pd.to_numeric(df[unixtime_col], errors='coerce')\n",
    "\n",
    "    if (df[time_col] == 0).any():\n",
    "        return df\n",
    "\n",
    "    first = df.iloc[0].copy()\n",
    "    new = first.copy()\n",
    "    new[time_col] = 0\n",
    "    new[unixtime_col] = first[unixtime_col] - int(first[time_col] * 1000)\n",
    "    return pd.concat([pd.DataFrame([new]), df], ignore_index=True)\n",
    "\n",
    "def frame_signal(data: np.ndarray, window_length: int, hop_length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Split a 2D array into overlapping frames via stride tricks.\n",
    "    \"\"\"\n",
    "    if data.shape[0] < window_length:\n",
    "        pad_n = window_length - data.shape[0]\n",
    "        pad = np.zeros((pad_n, data.shape[1]), dtype=data.dtype)\n",
    "        data = np.vstack([data, pad])\n",
    "\n",
    "    n_frames = 1 + (data.shape[0] - window_length) // hop_length\n",
    "    shape = (n_frames, window_length, data.shape[1])\n",
    "    strides = (hop_length * data.strides[0],) + data.strides\n",
    "    return as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "def rebuild_waveform(df: pd.DataFrame) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Convert multi-column audio data into flattened waveform and return start time.\n",
    "    \"\"\"\n",
    "    audio_cols = [c for c in df.columns if c.startswith('AudioData')]\n",
    "    arr = df[audio_cols].to_numpy(dtype=np.int16)\n",
    "    times = df['UnixTime_s'].to_numpy()\n",
    "    return arr.flatten(), float(times[0])\n",
    "\n",
    "def generate_mel_chunks(waveform: np.ndarray,\n",
    "                        sr: int = 16000,\n",
    "                        lower_edge_hz: int = 10,\n",
    "                        upper_edge_hz: int = 8000,\n",
    "                        chunk_secs: int = 600) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute mel spectrogram chunks for large waveform in time slices.\n",
    "    \"\"\"\n",
    "    chunk_samples = int(chunk_secs * sr)\n",
    "    mel_list = []\n",
    "\n",
    "    for start in tqdm(range(0, len(waveform), chunk_samples)):\n",
    "        chunk = waveform[start:start + chunk_samples]\n",
    "        if chunk.size == 0:\n",
    "            break\n",
    "        mel = vggish_input.wavform_to_concat_examples(\n",
    "            chunk, lower_edge_hz, upper_edge_hz, sr\n",
    "        )\n",
    "        mel_list.append(mel)\n",
    "\n",
    "    return np.concatenate(mel_list, axis=0)\n",
    "\n",
    "def proportional_oversample(sensor_arr: np.ndarray,\n",
    "                             intervals: List[Tuple[float, float, str]],\n",
    "                             target_act: str,\n",
    "                             window_length: int,\n",
    "                             hop_step: int,\n",
    "                             factor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate additional frames for under-represented activity by adjusting hop length.\n",
    "    \"\"\"\n",
    "    extra = []\n",
    "\n",
    "    for st, et, act in intervals:\n",
    "        if act != target_act:\n",
    "            continue\n",
    "\n",
    "        mask = (sensor_arr[:, 0] >= st) & (sensor_arr[:, 0] <= et)\n",
    "        seg = sensor_arr[mask]\n",
    "        if seg.shape[0] < window_length:\n",
    "            continue\n",
    "\n",
    "        orig = frame_signal(seg, window_length, hop_step)\n",
    "        Ni = orig.shape[0]\n",
    "        Mi = int(round((factor - 1) * Ni))\n",
    "        if Mi <= 0:\n",
    "            continue\n",
    "\n",
    "        new_hop = max(1, int(hop_step / factor))\n",
    "        pool = frame_signal(seg, window_length, new_hop)\n",
    "\n",
    "        replace = pool.shape[0] < Mi\n",
    "        idx = np.random.choice(pool.shape[0], Mi, replace=replace)\n",
    "        extra.append(pool[idx])\n",
    "\n",
    "    if extra:\n",
    "        return np.vstack(extra)\n",
    "    return np.empty((0, window_length, sensor_arr.shape[1]))\n",
    "\n",
    "# PREPROCESSING PIPELINE\n",
    "if __name__ == '__main__':\n",
    "    participants = [d.name for d in RAW_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "    for pid in participants:\n",
    "        raw_folder = RAW_DIR / pid\n",
    "        save_folder = SAVE_DIR / pid\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "        # Load and sync annotation & prediction\n",
    "        anno_file = next(raw_folder.glob('*annotation.csv'))\n",
    "        pred_file = next(raw_folder.glob('*Predicted_Activity.csv'))\n",
    "        anno_df = pd.read_csv(anno_file, on_bad_lines='skip')\n",
    "        pred_df = pd.read_csv(pred_file, on_bad_lines='skip')\n",
    "\n",
    "        # Harmonize activity names\n",
    "        anno_df['Activity'] = anno_df['Activity'].str.replace('Toothbrushing', 'Tooth_brushing')\n",
    "        pred_df['Predict'] = pred_df['Predict'].str.replace(' ', '_')\n",
    "\n",
    "        # Ensure time zero rows exist\n",
    "        anno_df = add_time_zero_row(anno_df)\n",
    "        pred_df = add_time_zero_row(pred_df)\n",
    "\n",
    "        # Sync UnixTime scales\n",
    "        delta = pred_df.loc[pred_df.Time == 0, 'UnixTime'].iat[0] - anno_df.loc[anno_df.Time == 0, 'UnixTime'].iat[0]\n",
    "        anno_df['UnixTime'] += delta\n",
    "\n",
    "        # Truncate annotation at prediction end and append stop event\n",
    "        end_unix = pred_df['UnixTime'].max()\n",
    "        anno_df = anno_df[anno_df['UnixTime'] <= end_unix]\n",
    "        stop = pred_df.loc[pred_df.UnixTime.idxmax()].to_dict()\n",
    "        stop.update({'Event': 'Session Stop', 'Activity': '', 'Confirm': ''})\n",
    "        anno_df = pd.concat([anno_df, pd.DataFrame([stop])], ignore_index=True)\n",
    "\n",
    "        # Convert UnixTime to seconds and compute intervals\n",
    "        anno_df['UnixTime_s'] = anno_df['UnixTime'] / 1000\n",
    "        intervals = []\n",
    "        stack = {}\n",
    "        for _, row in anno_df.query(\"Event not in ['Session Start','Session Stop']\").iterrows():\n",
    "            t, act = row.UnixTime_s, row.Activity\n",
    "            if row.Event == 'Start':\n",
    "                stack[act] = t\n",
    "            elif act in stack:\n",
    "                intervals.append((stack.pop(act), t, act))\n",
    "\n",
    "        # Process sensor data\n",
    "        imu_file = next(raw_folder.glob('*SensorData.csv'))\n",
    "        audio_file = next(raw_folder.glob('*AudioData.csv'))\n",
    "        sensor_df = pd.read_csv(imu_file, on_bad_lines='skip')\n",
    "        audio_df = pd.read_csv(audio_file, on_bad_lines='skip')\n",
    "\n",
    "        # Clean and synchronize data\n",
    "        sensor_df = sensor_df.dropna(subset=sensor_df.columns[:17]).reset_index(drop=True)\n",
    "        sensor_df = add_time_zero_row(sensor_df)\n",
    "        audio_df = add_time_zero_row(audio_df)\n",
    "        stop_ts = anno_df.loc[anno_df.Event == 'Session Stop', 'UnixTime'].iat[0]\n",
    "        sensor_df = sensor_df[sensor_df.UnixTime <= stop_ts]\n",
    "        audio_df = audio_df[audio_df.UnixTime <= stop_ts]\n",
    "        for df in (sensor_df, audio_df):\n",
    "            df['UnixTime_s'] = df['UnixTime'] / 1000\n",
    "\n",
    "        # Frame IMU data\n",
    "        imu_cols   = ['UnixTime_s','AccX','AccY','AccZ','GyroX','GyroY','GyroZ','RotVecX','RotVecY','RotVecZ']\n",
    "        imu_arr = sensor_df[imu_cols].to_numpy()\n",
    "        imu_sr     = 50\n",
    "        window_sec = 2.0\n",
    "        hop_sec    = 0.2\n",
    "        iwlen      = int(window_sec * imu_sr)\n",
    "        iwstep     = int(hop_sec * imu_sr)\n",
    "\n",
    "        imu_frames = frame_signal(imu_arr, iwlen, iwstep)\n",
    "\n",
    "        # Audio processing\n",
    "        waveform, audio_start = rebuild_waveform(audio_df)\n",
    "        mel_chunks = generate_mel_chunks(waveform)\n",
    "        n_mels = mel_chunks.shape[0]\n",
    "        hop = params.STFT_HOP_LENGTH_SECONDS\n",
    "        win = params.STFT_WINDOW_LENGTH_SECONDS\n",
    "        timestamps = audio_start + np.arange(n_mels) * hop + win\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:38<00:00,  4.37s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
