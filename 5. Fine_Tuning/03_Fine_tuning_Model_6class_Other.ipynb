{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T02:40:43.613944Z",
     "start_time": "2025-07-29T02:38:55.506842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOT = Path(\"../Data/Experiment_Data/3_PreprocessDataset_Oversample\")\n",
    "BASE_MODEL_PATH = Path(\"../Models/tensorflow_model/MultiModal/MultiModal_ver1/Right/MM_Scratch.h5\")\n",
    "OTHER_DATA_ROOT = Path(\"../Data/Train_Data/3_MMExamples\")\n",
    "OTHER_SUBJECTS = [\"101\", \"102\"]\n",
    "LABEL_BINARIZER_PATH = Path(\"../LabelBinarizer/Label_binarizer_6_classes.pkl\")\n",
    "NORM_PARAMS_PATH    = Path(\"../Normalization_params/Normalization_params_pickle/normalization_params_Right_ver1.pkl\")\n",
    "SAVE_TFLITE_DIR     = Path(\"../Models/Finetuned_Model/Finetune_model_6class_ver5/tflite\")\n",
    "\n",
    "TRAIN_SECONDS = [10, 30] + list(range(60, 481, 60))\n",
    "NOISE_SEC, VAL_SEC = 3, 10\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "SEED = 4\n",
    "CLASSES = [\"Shower\", \"Tooth_brushing\", \"Washing_hands\", \"Vacuum_Cleaner\", \"Wiping\", \"Other\"]\n",
    "\n",
    "# Utility Functions\n",
    "def compute_num_frames(duration: float, window: float = 2.0, hop: float = 0.2) -> int:\n",
    "    \"\"\"Compute number of overlapping frames for a segment.\"\"\"\n",
    "    if duration < window:\n",
    "        return 0\n",
    "    return 1 + int(math.floor((duration - window) / hop))\n",
    "\n",
    "# Load \"Other\" class data once\n",
    "other_imu_list = []\n",
    "other_audio_list = []\n",
    "for subj in OTHER_SUBJECTS:\n",
    "    subj_dir = OTHER_DATA_ROOT / subj / \"Right\" / \"16000\"\n",
    "    for pkl_file in sorted(subj_dir.glob(f\"{subj}---Other---*.pkl\")):\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            data = pkl.load(f)\n",
    "        other_imu_list.append(data['IMU'])\n",
    "        other_audio_list.append(data['audio'])\n",
    "other_imu_all = np.concatenate(other_imu_list, axis=0)\n",
    "other_audio_all = np.concatenate(other_audio_list, axis=0)\n",
    "print(f\"Loaded Other IMU {other_imu_all.shape}, Audio {other_audio_all.shape}\")\n",
    "\n",
    "# Main fine-tuning loop\n",
    "# Set seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Load base model, label binarizer, normalization params\n",
    "base_model = load_model(BASE_MODEL_PATH)\n",
    "with open(LABEL_BINARIZER_PATH, 'rb') as f:\n",
    "    lb = pkl.load(f)\n",
    "with open(NORM_PARAMS_PATH, 'rb') as f:\n",
    "    norm = pkl.load(f)\n",
    "pm, pn = norm['max'], norm['min']\n",
    "mean, std = norm['mean'], norm['std']\n",
    "\n",
    "# Precompute frame counts\n",
    "noise_frames = compute_num_frames(NOISE_SEC)\n",
    "val_frames = compute_num_frames(VAL_SEC)\n",
    "\n",
    "for train_sec in TRAIN_SECONDS:\n",
    "    train_frames = compute_num_frames(train_sec)\n",
    "\n",
    "    for pid_dir in sorted(DATA_ROOT.iterdir()):\n",
    "        if not pid_dir.is_dir():\n",
    "            continue\n",
    "        pid = pid_dir.name\n",
    "        print(f\"\\n>>> Participant: {pid}, window: {train_sec}s\")\n",
    "\n",
    "        # Load participant data\n",
    "        with open(pid_dir / f\"{pid}_preprocessing.pkl\", 'rb') as f:\n",
    "            pdata = pkl.load(f)\n",
    "        imu_data = pdata['IMU']  # shape (N, T, F)\n",
    "        audio_data = pdata['Audio']  # shape (N, n_mel, m)\n",
    "        labels = pdata['Activity']\n",
    "\n",
    "        # Split indices for classes except 'Other'\n",
    "        train_idx_pc = []\n",
    "        val_idx_pc = []\n",
    "        for cls in CLASSES[:-1]:  # all except Other\n",
    "            idxs = np.where(labels == cls)[0]\n",
    "            diffs = np.diff(idxs)\n",
    "            breaks = np.where(diffs != 1)[0]\n",
    "            starts = np.concatenate(([0], breaks+1))\n",
    "            ends = np.concatenate((breaks, [len(idxs)-1]))\n",
    "            selected = []\n",
    "            for s, e in zip(starts, ends):\n",
    "                segment = idxs[s:e+1]\n",
    "                if segment.size > noise_frames:\n",
    "                    selected.append(segment[noise_frames:])\n",
    "            if selected:\n",
    "                allseg = np.concatenate(selected)\n",
    "            else:\n",
    "                allseg = np.array([], dtype=int)\n",
    "            limited = allseg[:train_frames + val_frames]\n",
    "            train_idx_pc.append(limited[:train_frames])\n",
    "            val_idx_pc.append(limited[train_frames:])\n",
    "        train_idx_pc = np.sort(np.concatenate(train_idx_pc)) if train_idx_pc else np.array([], dtype=int)\n",
    "        val_idx_pc = np.sort(np.concatenate(val_idx_pc)) if val_idx_pc else np.array([], dtype=int)\n",
    "\n",
    "        # Randomly sample 'Other' from external pool\n",
    "        total_needed = train_frames + val_frames\n",
    "        if other_imu_all.shape[0] < total_needed:\n",
    "            raise ValueError(\"Not enough Other samples\")\n",
    "        ot_choices = np.random.choice(other_imu_all.shape[0], total_needed, replace=False)\n",
    "        train_idx_ot = ot_choices[:train_frames]\n",
    "        val_idx_ot = ot_choices[train_frames:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Assemble training and validation sets\n",
    "        X_imu_tr = np.concatenate([imu_data[train_idx_pc], other_imu_all[train_idx_ot]], axis=0)\n",
    "        X_audio_tr = np.concatenate([audio_data[train_idx_pc], other_audio_all[train_idx_ot]], axis=0)\n",
    "        y_tr = np.concatenate([labels[train_idx_pc], np.array(['Other']*train_frames)], axis=0)\n",
    "\n",
    "        X_imu_val = np.concatenate([imu_data[val_idx_pc], other_imu_all[val_idx_ot]], axis=0)\n",
    "        X_audio_val = np.concatenate([audio_data[val_idx_pc], other_audio_all[val_idx_ot]], axis=0)\n",
    "        y_val = np.concatenate([labels[val_idx_pc], np.array(['Other']*val_frames)], axis=0)\n",
    "\n",
    "        # Shuffle training set\n",
    "        perm = np.random.permutation(len(y_tr))\n",
    "        X_imu_tr, X_audio_tr, y_tr = X_imu_tr[perm], X_audio_tr[perm], y_tr[perm]\n",
    "\n",
    "        # One-hot encoding labels\n",
    "        y_tr_enc = lb.transform(y_tr)\n",
    "        y_val_enc = lb.transform(y_val)\n",
    "\n",
    "        # Normalize IMU data\n",
    "        def norm_imu(x):\n",
    "            scaled = 1 + (x - pm.reshape(1,1,-1)) * 2 / (pm.reshape(1,1,-1) - pn.reshape(1,1,-1))\n",
    "            return ((scaled - mean.reshape(1,1,-1)) / std.reshape(1,1,-1)).astype('float32')\n",
    "\n",
    "        X_imu_tr = norm_imu(X_imu_tr)\n",
    "        X_imu_val = norm_imu(X_imu_val)\n",
    "        X_audio_tr = X_audio_tr.astype('float32')\n",
    "        X_audio_val = X_audio_val.astype('float32')\n",
    "\n",
    "        # Fine-tune model\n",
    "        model = clone_model(base_model)\n",
    "        model.set_weights(base_model.get_weights())\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "        model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Early-stopping\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        history = model.fit(\n",
    "            [X_imu_tr, X_audio_tr], y_tr_enc,\n",
    "            validation_data=([X_imu_val, X_audio_val], y_val_enc),\n",
    "            epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "            callbacks=[es], verbose=2\n",
    "        )\n",
    "\n",
    "        # Convert to TFLite\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        save_dir = SAVE_TFLITE_DIR / pid\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (save_dir / f\"Finetune_other_{train_sec}s.tflite\").write_bytes(tflite_model)\n",
    "\n",
    "        print(f\"Done {pid} | window={train_sec}s -- saved to {save_dir}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Other IMU (160650, 100, 9), Audio (160650, 96, 64)\n",
      "\n",
      ">>> Participant: 201, window: 10s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 1 and the array at index 1 has size 9",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_28268\\1074177709.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;31m# Assemble training and validation sets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m         \u001B[0mX_imu_tr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mimu_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_idx_pc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother_imu_all\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_idx_ot\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[0mX_audio_tr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0maudio_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_idx_pc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother_audio_all\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_idx_ot\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[0my_tr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_idx_pc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Other'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mtrain_frames\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 1 and the array at index 1 has size 9"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T02:42:21.294484Z",
     "start_time": "2025-07-29T02:42:21.281485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(imu_data[train_idx_pc].shape)\n",
    "print(other_imu_all[train_idx_ot].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 100, 1)\n",
      "(41, 100, 9)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T02:42:38.317065Z",
     "start_time": "2025-07-29T02:42:38.297065Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137593, 100, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
