{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random Forest Feature Extraction & ONNX Pipeline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ROOT = Path(\"../..\")\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'Data/Train_Data/3_MMExamples'\n",
    "NORM_PATH = PROJECT_ROOT / f\"Normalization_params/Normalization_params_pickle/normalization_params_Right_ver1.pkl\"\n",
    "ONNX_DIR = PROJECT_ROOT / 'Models/Onnx_model'\n",
    "ONNX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PIDS = [10, 100, 101, 102, 103]\n",
    "TEST_PIDS = [3]\n",
    "HAND = 'Right'\n",
    "SR = '16000'\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "# Feature configuration\n",
    "SENSORS = ['Acc', 'Gyro', 'Rotvec']\n",
    "AXES = ['x', 'y', 'z']\n",
    "FEATURE_FUNCS = [np.mean, np.std, np.max, np.min, np.median, np.var, skew, kurtosis]\n",
    "\n",
    "#  Utility Functions\n",
    "def extract_features(window: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract statistical features for each axis in the window.\"\"\"\n",
    "    feats = []\n",
    "    for i in range(window.shape[1]):\n",
    "        col = window[:, i]\n",
    "        feats.extend([func(col) for func in FEATURE_FUNCS])\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "def load_preprocess(pids, norm_params) -> (pd.DataFrame, pd.Series):\n",
    "    \"\"\"Load IMU pickle files, normalize, and extract features.\"\"\"\n",
    "    max_, min_, mean_, std_ = [norm_params[k] for k in ('max','min','mean','std')]\n",
    "    # reshape parameters\n",
    "    max_, min_, mean_, std_ = [p.reshape(1,1,-1) for p in (max_, min_, mean_, std_)]\n",
    "\n",
    "    rows, labels = [], []\n",
    "\n",
    "    for pid in pids:\n",
    "        folder = DATA_DIR / str(pid) / HAND / SR\n",
    "        for file in folder.glob('*.pkl'):\n",
    "            pid_s, activity, trial = file.stem.split('---')\n",
    "            data = pkl.load(open(file,'rb'))['IMU']\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "            # normalize\n",
    "            norm = 1 + (data - max_) * 2 / (max_ - min_)\n",
    "            norm = (norm - mean_) / std_\n",
    "            # extract per-frame features\n",
    "            for window in norm:\n",
    "                feats = extract_features(window)\n",
    "                rows.append(feats)\n",
    "                labels.append(activity)\n",
    "\n",
    "    cols = [f\"{s}_{a}_{f.__name__}\" for s in SENSORS for a in AXES for f in FEATURE_FUNCS]\n",
    "    return pd.DataFrame(rows, columns=cols), pd.Series(labels, name='activity')\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    # Load normalization parameters\n",
    "    norm_params = pkl.load(open(NORM_PATH, 'rb'))\n",
    "\n",
    "    # Load train and test\n",
    "    X_train_df, y_train = load_preprocess(TRAIN_PIDS, norm_params)\n",
    "    X_test_df, y_test = load_preprocess(TEST_PIDS, norm_params)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "\n",
    "    # Compute class weights\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(y_train_enc), y=y_train_enc)\n",
    "    class_wt = dict(enumerate(cw))\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=50,\n",
    "                                class_weight=class_wt)\n",
    "    rf.fit(X_train_df.values, y_train_enc)\n",
    "\n",
    "    # Evaluate Scikit-learn model\n",
    "    y_pred = rf.predict(X_test_df.values)\n",
    "    ba = balanced_accuracy_score(y_test_enc, y_pred)\n",
    "    f1w = f1_score(y_test_enc, y_pred, average='weighted')\n",
    "    print(f\"Test Balanced Accuracy: {ba:.4f}\")\n",
    "    print(f\"Test Weighted F1 Score: {f1w:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test_enc, y_pred)\n",
    "    cm_pct = cm.astype(float) / cm.sum(axis=1)[:,None] * 100\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    im = ax.imshow(cm_pct, cmap='Blues', vmin=0, vmax=100)\n",
    "    fig.colorbar(im, ax=ax, label='Percent')\n",
    "    ticks = np.arange(len(le.classes_))\n",
    "    ax.set_xticks(ticks); ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(le.classes_, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(le.classes_)\n",
    "    thresh = cm_pct.max()/2\n",
    "    for i in range(cm_pct.shape[0]):\n",
    "        for j in range(cm_pct.shape[1]):\n",
    "            color = 'white' if cm_pct[i,j]>thresh else 'black'\n",
    "            ax.text(j, i, f\"{cm_pct[i,j]:.1f}%\", ha='center', va='center', color=color)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Convert and save ONNX\n",
    "    initial_type = [('float_input', FloatTensorType([None, X_train_df.shape[1]]))]\n",
    "    onnx_model = convert_sklearn(rf, initial_types=initial_type, target_opset=8)\n",
    "    onnx_path = ONNX_DIR / f\"random_forest_ver{MODEL_VERSION}.onnx\"\n",
    "    with open(onnx_path, 'wb') as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    print(f\"Saved ONNX model to {onnx_path}\")\n",
    "\n",
    "    # ONNX inference test\n",
    "    sess = ort.InferenceSession(str(onnx_path))\n",
    "    inp_name = sess.get_inputs()[0].name\n",
    "    out_name = sess.get_outputs()[0].name\n",
    "    preds_onnx = sess.run([out_name], {inp_name: X_test_df.values.astype(np.float32)})[0]\n",
    "    ba2 = balanced_accuracy_score(y_test, preds_onnx)\n",
    "    f1m = f1_score(y_test, preds_onnx, average='macro')\n",
    "    print(f\"ONNX Test Balanced Accuracy: {ba2:.4f}\")\n",
    "    print(f\"ONNX Test Macro F1 Score:    {f1m:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
