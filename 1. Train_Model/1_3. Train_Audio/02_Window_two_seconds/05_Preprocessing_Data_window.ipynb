{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from utils import vggish_input, params\n",
    "\n",
    "# Configurations\n",
    "DATA_DIR = Path(\"../../Data/Experiment_Data/1. RawDataset\")\n",
    "ANNO_DIR = Path(\"../../Data/Experiment_Data/2. PreprocessDataset\")\n",
    "SAVE_DIR = Path(\"../../Data/Experiment_Data/5. PreprocessDataset_Window_Audio\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "IMU_SR = 50\n",
    "WINDOW_SEC = 2.0\n",
    "HOP_SEC = 0.2\n",
    "SUB_SR = 16000\n",
    "CHUNK_HOURS = 1\n",
    "\n",
    "CLASS_LIST = ['Tooth_brushing', 'Washing_hands', 'Shower', 'Wiping', 'Vacuum_Cleaner', 'Other']\n",
    "\n",
    "# Helpers\n",
    "def add_time_zero_row(df, tcol='Time', ucol='UnixTime'):\n",
    "    df = df.copy()\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors='coerce')\n",
    "    df[ucol] = pd.to_numeric(df[ucol], errors='coerce')\n",
    "    if (df[tcol] == 0).any():\n",
    "        return df\n",
    "    first = df.iloc[0].copy()\n",
    "    first[ucol] -= int(first[tcol] * 1000)\n",
    "    first[tcol] = 0\n",
    "    return pd.concat([first.to_frame().T, df], ignore_index=True)\n",
    "\n",
    "\n",
    "def frame(data, win_len, hop_len):\n",
    "    n = data.shape[0]\n",
    "    if n < win_len:\n",
    "        pad = win_len - n\n",
    "        data = np.vstack([data, np.zeros((pad, data.shape[1]))])\n",
    "    n_frames = 1 + (data.shape[0] - win_len) // hop_len\n",
    "    shape = (n_frames, win_len, data.shape[1])\n",
    "    strides = (hop_len * data.strides[0],) + data.strides\n",
    "    return as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def rebuild_waveform(df):\n",
    "    audio_cols = [c for c in df.columns if c.startswith('AudioData')]\n",
    "    arr = df[audio_cols].to_numpy(dtype=np.int16)\n",
    "    return arr.flatten(), df['UnixTime_s'].iloc[0]\n",
    "\n",
    "\n",
    "def generate_mel_chunks(wav, sr, low, high, hours):\n",
    "    samples_per_chunk = int(hours * 3600 * sr)\n",
    "    mel_list = []\n",
    "    for start in tqdm(range(0, len(wav), samples_per_chunk)):\n",
    "        chunk = wav[start:start + samples_per_chunk]\n",
    "        if chunk.size == 0:\n",
    "            break\n",
    "        mel = vggish_input.wavform_to_concat_examples(\n",
    "            chunk, lower_edge_hertz=low, upper_edge_hertz=high, sr=sr)\n",
    "        mel_list.append(mel)\n",
    "    return np.concatenate(mel_list, axis=0)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for pid in sorted(os.listdir(DATA_DIR)):\n",
    "    pdir = DATA_DIR / pid\n",
    "    if not pdir.is_dir():\n",
    "        continue\n",
    "    print(f\"Processing {pid}...\")\n",
    "\n",
    "    # Load dataframes\n",
    "    sensor = pd.read_csv(next(pdir.glob(\"*SensorData.csv\")), engine='python')\n",
    "    audio  = pd.read_csv(next(pdir.glob(\"*AudioData.csv\")), engine='python')\n",
    "    anno   = pd.read_csv(ANNO_DIR / pid / f\"{pid}_Annotation_processed.csv\")\n",
    "\n",
    "    # Clean sensor noise\n",
    "    exp = sensor.columns[:17]\n",
    "    extra = sensor.columns[17:]\n",
    "    mask = sensor[exp].isnull().any(axis=1) | sensor[extra].notnull().any(axis=1)\n",
    "    sensor = sensor.loc[~mask].reset_index(drop=True)\n",
    "\n",
    "    # Zero-time rows\n",
    "    sensor = add_time_zero_row(sensor)\n",
    "    audio  = add_time_zero_row(audio)\n",
    "\n",
    "    # Sync timestamps\n",
    "    t0_s = sensor.loc[sensor.Time==0, 'UnixTime'].iloc[0]\n",
    "    t0_a = audio .loc[audio .Time==0, 'UnixTime'].iloc[0]\n",
    "    t0_n = anno  .loc[anno  .Time==0, 'UnixTime'].iloc[0]\n",
    "    audio['UnixTime'] += (t0_s - t0_a)\n",
    "    anno ['UnixTime'] += (t0_s - t0_n)\n",
    "\n",
    "    # Filter by session stop\n",
    "    endux = anno.loc[anno.Event=='Session Stop','UnixTime'].max()\n",
    "    sensor = sensor[sensor.UnixTime <= endux].reset_index(drop=True)\n",
    "    audio  = audio [audio .UnixTime <= endux].reset_index(drop=True)\n",
    "\n",
    "    # Convert to seconds\n",
    "    for df in (sensor, audio, anno):\n",
    "        df['UnixTime_s'] = df['UnixTime'] / 1000.0\n",
    "\n",
    "    # IMU frames\n",
    "    imu_arr = sensor[['UnixTime_s','AccX','AccY','AccZ','GyroX','GyroY','GyroZ','RotVecX','RotVecY','RotVecZ']].to_numpy()\n",
    "    wlen = int(WINDOW_SEC * IMU_SR)\n",
    "    hlen = int(HOP_SEC * IMU_SR)\n",
    "    imu_frames = frame(imu_arr, wlen, hlen)\n",
    "\n",
    "    # Build intervals\n",
    "    intervals = []\n",
    "    stack = {}\n",
    "    for _, r in anno.query(\"Event!='Session Start' and Event!='Session Stop'\").iterrows():\n",
    "        t, ev, act = r.UnixTime_s, r.Event, r.Activity\n",
    "        if ev == 'Start':\n",
    "            stack[act] = t\n",
    "        elif ev=='End' and act in stack:\n",
    "            intervals.append((stack.pop(act), t, act))\n",
    "\n",
    "    # Rebuild waveform & mel chunks\n",
    "    wav, start = rebuild_waveform(audio)\n",
    "    mel = generate_mel_chunks(wav, SUB_SR, 10, SUB_SR//2, CHUNK_HOURS)\n",
    "\n",
    "    # Timestamp for mel frames\n",
    "    mel_hop = params.STFT_HOP_LENGTH_SECONDS_2sec\n",
    "    mel_win = params.STFT_WINDOW_LENGTH_SECONDS_2sec\n",
    "    n_mels = mel.shape[0]\n",
    "    ts = start + np.arange(n_mels)*mel_hop + mel_win\n",
    "\n",
    "    # Windowed examples & labels\n",
    "    ex_len = int(params.EXAMPLE_WINDOW_SECONDS_2sec / mel_hop)\n",
    "    X, Y = [], []\n",
    "    for f in imu_frames:\n",
    "        s_t, e_t = f[0,0], f[-1,0]\n",
    "        i0 = np.searchsorted(ts, s_t)\n",
    "        i1 = i0 + ex_len\n",
    "        if i1 > n_mels:\n",
    "            continue\n",
    "        seg = mel[i0:i1]\n",
    "        if seg.shape[0] < ex_len:\n",
    "            pad = ex_len - seg.shape[0]\n",
    "            seg = np.vstack([seg, np.zeros((pad, seg.shape[1]))])\n",
    "        # Label by overlap\n",
    "        counts = {c:0 for c in CLASS_LIST}\n",
    "        for st, et, ac in intervals:\n",
    "            counts[ac] += max(0, min(e_t, et)-max(s_t, st))\n",
    "        covered = sum(counts.values())\n",
    "        counts['Other'] += max(0, (e_t-s_t)-covered)\n",
    "        label = max(counts, key=counts.get)\n",
    "        X.append(seg)\n",
    "        Y.append(label)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    Y = np.array(Y)\n",
    "    print(pid, 'â†’', X.shape, Y.shape)\n",
    "\n",
    "    # Save\n",
    "    out = SAVE_DIR / pid\n",
    "    out.mkdir(exist_ok=True)\n",
    "    with open(out / f\"{pid}_preprocessing.pkl\", 'wb') as f:\n",
    "        pkl.dump({'Audio':X, 'Activity':Y}, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
