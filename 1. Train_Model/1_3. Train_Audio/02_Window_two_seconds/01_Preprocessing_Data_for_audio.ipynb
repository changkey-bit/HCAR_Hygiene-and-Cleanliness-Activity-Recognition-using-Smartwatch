{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Raw IMU & Audio CSV → Pickle Preprocessing Pipeline\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import vggish_input, params\n",
    "\n",
    "# ── Configuration ──\n",
    "RAW_DIR    = Path(\"../../Data/Pilot_Data/1. RawDataset\")\n",
    "SAVE_DIR   = Path(\"../../Data/Pilot_Data/3. PreprocessDataset_for_Audio\")\n",
    "PID        = \"16\"\n",
    "SR         = 16000\n",
    "LE_HZ      = params.MEL_MIN_HZ\n",
    "UE_HZ      = params.MEL_MAX_HZ\n",
    "\n",
    "# ── Helpers ──\n",
    "def add_time_zero(df, time_col='Time', ux_col='UnixTime'):\n",
    "    df = df.copy()\n",
    "    if (df[time_col] == 0).any():\n",
    "        return df\n",
    "    first = df.iloc[0].copy()\n",
    "    offset = int(first[time_col] * 1000)\n",
    "    new = first.copy()\n",
    "    new[time_col] = 0\n",
    "    new[ux_col]   = first[ux_col] - offset\n",
    "    return pd.concat([pd.DataFrame([new]), df], ignore_index=True)\n",
    "\n",
    "\n",
    "def load_csvs(pid):\n",
    "    base = RAW_DIR / pid\n",
    "    imu_f = next(base.glob(\"*SensorData.csv\"))\n",
    "    aud_f = next(base.glob(\"*AudioData.csv\"))\n",
    "    ann_f = next(base.glob(\"*annotation_modified.csv\"))\n",
    "    imu_df  = pd.read_csv(imu_f)\n",
    "    aud_df  = pd.read_csv(aud_f)\n",
    "    ann_df  = pd.read_csv(ann_f)\n",
    "    return imu_df, aud_df, ann_df\n",
    "\n",
    "\n",
    "def sync_and_trim(imu_df, aud_df, ann_df):\n",
    "    imu_df = add_time_zero(imu_df)\n",
    "    aud_df = add_time_zero(aud_df)\n",
    "    ann_df = add_time_zero(ann_df)\n",
    "\n",
    "    zero_imu = imu_df.loc[imu_df.Time==0, 'UnixTime'].iloc[0]\n",
    "    zero_ann = ann_df.loc[ann_df.Time==0, 'UnixTime'].iloc[0]\n",
    "    ann_df['UnixTime'] += zero_imu - zero_ann\n",
    "\n",
    "    end_ts = ann_df.query(\"Event=='session_stop'\").UnixTime.max()\n",
    "    imu_df = imu_df[imu_df.UnixTime <= end_ts].reset_index(drop=True)\n",
    "    aud_df = aud_df[aud_df.UnixTime <= end_ts].reset_index(drop=True)\n",
    "    return imu_df, aud_df, ann_df\n",
    "\n",
    "\n",
    "def extract_intervals(ann_df):\n",
    "    df = ann_df.query(\"Event.isin(['start','stop'])\").reset_index(drop=True)\n",
    "    stack, intervals = {}, []\n",
    "    for _, r in df.iterrows():\n",
    "        t, act, ev = r.UnixTime, r.Activity, r.Event\n",
    "        if ev=='start': stack[act] = t\n",
    "        elif ev=='stop' and act in stack:\n",
    "            intervals.append((stack.pop(act), t, act))\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def label_audio_runs(aud_df, intervals):\n",
    "    aud = aud_df.copy()\n",
    "    aud['Activity'] = 'Other'\n",
    "    cols = [c for c in aud.columns if c.startswith('AudioData')]\n",
    "    for st, et, act in intervals:\n",
    "        mask = aud.UnixTime.between(st, et)\n",
    "        aud.loc[mask, 'Activity'] = act\n",
    "    aud['run_id'] = (aud.Activity != aud.Activity.shift()).cumsum()\n",
    "    samples = []\n",
    "    for _, grp in aud.groupby('run_id'):\n",
    "        arr = grp[cols].to_numpy(dtype=np.int16).flatten()\n",
    "        lbl = grp.Activity.iat[0]\n",
    "        samples.append((arr, lbl))\n",
    "    return samples\n",
    "\n",
    "def window_and_save(samples, pid):\n",
    "    save_d = SAVE_DIR / pid\n",
    "    save_d.mkdir(parents=True, exist_ok=True)\n",
    "    audio_windows, labels = [], []\n",
    "    for wav, lbl in tqdm(samples, desc=\"Windowing audio\"):\n",
    "        feats = vggish_input.wavform_to_examples(\n",
    "            wav, lower_edge_hertz=LE_HZ, upper_edge_hertz=UE_HZ, sr=SR\n",
    "        )\n",
    "        audio_windows.append(feats)\n",
    "        labels += [lbl] * feats.shape[0]\n",
    "    X = np.vstack(audio_windows)\n",
    "    y = np.array(labels)\n",
    "    with open(save_d / f\"{pid}_preprocessing_for_audio.pkl\", 'wb') as f:\n",
    "        pickle.dump({'Audio':X, 'Activity':y}, f)\n",
    "    print(f\"Saved {X.shape} + {y.shape} to {save_d}\")\n",
    "\n",
    "\n",
    "# ── Pipeline ──\n",
    "imu_df, aud_df, ann_df = load_csvs(PID)\n",
    "imu_df, aud_df, ann_df = sync_and_trim(imu_df, aud_df, ann_df)\n",
    "intervals = extract_intervals(ann_df)\n",
    "samples = label_audio_runs(aud_df, intervals)\n",
    "window_and_save(samples, PID)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
