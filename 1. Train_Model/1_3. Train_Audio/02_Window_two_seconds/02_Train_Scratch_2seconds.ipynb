{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Raw IMU & Audio CSV â†’ Pickle Audio Preprocessing\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import vggish_input\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOT = Path(\"../../Data/Pilot_Data/1. RawDataset\")\n",
    "SAVE_ROOT = Path(\"../../Data/Pilot_Data/3. PreprocessDataset_for_Audio\")\n",
    "PARTICIPANT = '16'\n",
    "IMU_SUFFIX = 'SensorData.csv'\n",
    "AUDIO_SUFFIX = 'AudioData.csv'\n",
    "ANNO_SUFFIX = 'annotation_modified.csv'\n",
    "SUB_SR = 16000\n",
    "LEH, UEH = 10, SUB_SR//2\n",
    "\n",
    "# Utilities\n",
    "def add_time_zero(df, time_col='Time', ux_col='UnixTime'):\n",
    "    if (df[time_col]==0).any():\n",
    "        return df\n",
    "    first = df.iloc[0].copy()\n",
    "    new = first.copy()\n",
    "    new[time_col]=0\n",
    "    new[ux_col]=first[ux_col] - int(first[time_col]*1000)\n",
    "    return pd.concat([new.to_frame().T, df], ignore_index=True)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    base = DATA_ROOT / PARTICIPANT\n",
    "    imu_file = next(p for p in base.iterdir() if p.name.endswith(IMU_SUFFIX))\n",
    "    audio_file = next(p for p in base.iterdir() if p.name.endswith(AUDIO_SUFFIX))\n",
    "    anno_file = next(p for p in base.iterdir() if p.name.endswith(ANNO_SUFFIX))\n",
    "\n",
    "    df_imu = pd.read_csv(imu_file); df_imu = add_time_zero(df_imu)\n",
    "    df_audio = pd.read_csv(audio_file); df_audio = add_time_zero(df_audio)\n",
    "    df_anno = pd.read_csv(anno_file)\n",
    "\n",
    "    # align annotations to IMU time zero\n",
    "    imu0 = df_imu.loc[df_imu.Time==0,'UnixTime'].iloc[0]\n",
    "    anno0 = df_anno.loc[df_anno.Time==0,'UnixTime'].iloc[0]\n",
    "    df_anno.UnixTime += (imu0 - anno0)\n",
    "    # end time\n",
    "    end = df_anno.loc[df_anno.Event=='session_stop','UnixTime'].iloc[0]\n",
    "\n",
    "    # trim IMU & audio to session\n",
    "    df_imu = df_imu[df_imu.UnixTime<=end]\n",
    "    df_audio = df_audio[df_audio.UnixTime<=end]\n",
    "    return df_imu, df_audio, df_anno\n",
    "\n",
    "\n",
    "def extract_intervals(df_anno):\n",
    "    df = df_anno[df_anno.Event.isin(['start','stop'])]\n",
    "    stack={} ; intervals=[]\n",
    "    for _,r in df.iterrows():\n",
    "        if r.Event=='start': stack[r.Activity]=r.UnixTime\n",
    "        elif r.Event=='stop' and r.Activity in stack:\n",
    "            intervals.append((stack.pop(r.Activity), r.UnixTime, r.Activity))\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def label_audio(df_audio, intervals):\n",
    "    df = df_audio.copy()\n",
    "    df['Activity']='Other'\n",
    "    audio_cols = [c for c in df.columns if c.startswith('AudioData')]\n",
    "    for st,et,act in intervals:\n",
    "        mask = (df.UnixTime>=st)&(df.UnixTime<=et)\n",
    "        df.loc[mask,'Activity']=act\n",
    "    df['run_id'] = (df.Activity!=df.Activity.shift()).cumsum()\n",
    "    samples, labels = [], []\n",
    "    for _,grp in df.groupby('run_id'):\n",
    "        arr = grp[audio_cols].to_numpy(dtype=np.int16).flatten()\n",
    "        samples.append(arr); labels.append(grp.Activity.iloc[0])\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "def window_and_save(samples, labels):\n",
    "    audio_windows=[]; audio_labels=[]\n",
    "    for arr,label in zip(samples, labels):\n",
    "        mel = vggish_input.wavform_to_examples(arr, lower_edge_hertz=LEH, upper_edge_hertz=UEH, sr=SUB_SR)\n",
    "        audio_windows.append(mel)\n",
    "        audio_labels += [label]*mel.shape[0]\n",
    "    X = np.concatenate(audio_windows,axis=0)\n",
    "    y = np.array(audio_labels)\n",
    "    # save\n",
    "    out_dir = SAVE_ROOT / PARTICIPANT\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    with open(out_dir/f'{PARTICIPANT}_preprocessing_for_audio.pkl','wb') as f:\n",
    "        pickle.dump({'Audio':X,'Activity':y}, f)\n",
    "    print(f\"Saved {X.shape} examples with labels {set(y)}\")\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    df_imu, df_audio, df_anno = load_data()\n",
    "    intervals = extract_intervals(df_anno)\n",
    "    samples, labels = label_audio(df_audio, intervals)\n",
    "    window_and_save(samples, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
