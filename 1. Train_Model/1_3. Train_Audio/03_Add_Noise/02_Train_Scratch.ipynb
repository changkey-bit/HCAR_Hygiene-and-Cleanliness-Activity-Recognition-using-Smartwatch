{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Preprocess & Train Audio Model with Clean + Noisy Examples\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "random.seed(4)\n",
    "np.random.seed(4)\n",
    "tf.random.set_seed(4)\n",
    "\n",
    "MODEL_VERSION = 36\n",
    "TRAIN_IDS = [10, 100, 101, 102, 103]\n",
    "VALID_IDS = [104]\n",
    "TEST_IDS = [3, 4]\n",
    "HAND = 'Right'\n",
    "SR = 16_000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "EXAMPLE_MODEL_PATH = Path(\"../../Models/Reference_Model/example_model.hdf5\")\n",
    "CLEAN_DATA_ROOT = Path(\"../../Data/Train_Data/4. AudioExamples/01_Original\")\n",
    "NOISE_DATA_ROOT = Path(\"../../Data/Train_Data/6. AudioExamples_noise\")\n",
    "OUTPUT_MODEL_ROOT = Path(f\"../../Models/tensorflow_model/Audio/Audio_noise_ver{MODEL_VERSION}\")\n",
    "METRICS_ROOT = Path(f\"../../Result/Train_Result/Model_Accuracy/Audio/Audio_noise_ver{MODEL_VERSION}\")\n",
    "PREDICTIONS_ROOT = Path(f\"../../Result/Model_Preds/Audio/Audio_noise_ver{MODEL_VERSION}\")\n",
    "\n",
    "# Create output directories\n",
    "for d in (OUTPUT_MODEL_ROOT, METRICS_ROOT, PREDICTIONS_ROOT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_examples(ids, root: Path):\n",
    "    \"\"\"Load examples and labels for given participant IDs from `root`.\"\"\"\n",
    "    X_list, y_list = [], []\n",
    "    for pid in ids:\n",
    "        dir_path = root / str(pid) / HAND / str(SR)\n",
    "        if not dir_path.is_dir():\n",
    "            continue\n",
    "        for pkl in dir_path.glob(\"*.pkl\"):\n",
    "            pid_str, activity, trial = pkl.stem.split(\"---\")\n",
    "            data = pickle.load(open(pkl, \"rb\"))\n",
    "            X_list.append(data)\n",
    "            y_list += [[pid_str, activity, trial]] * data.shape[0]\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_combined(ids):\n",
    "    \"\"\"Combine clean and noisy examples for training/validation.\"\"\"\n",
    "    Xc, yc = load_examples(ids, CLEAN_DATA_ROOT)\n",
    "    Xn, yn = load_examples(ids, NOISE_DATA_ROOT)\n",
    "    return np.vstack([Xc, Xn]), np.vstack([yc, yn])\n",
    "\n",
    "\n",
    "def build_finetuned_model(num_classes=5):\n",
    "    \"\"\"\n",
    "    Load a pretrained reference model,\n",
    "    replace its final layer to match `num_classes`,\n",
    "    and compile it.\n",
    "    \"\"\"\n",
    "    base = tf.keras.models.load_model(EXAMPLE_MODEL_PATH)\n",
    "    x = base.layers[-2].output\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base.input, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def data_generator(X, y, batch_size, shuffle=True):\n",
    "    \"\"\"Yield batches of `[X], y` for Keras `.fit`.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        for start in range(0, n, batch_size):\n",
    "            batch = indices[start:start + batch_size]\n",
    "            yield [X[batch]], y[batch]\n",
    "\n",
    "\n",
    "X_train, y_train = load_combined(TRAIN_IDS)\n",
    "X_val, y_val = load_combined(VALID_IDS)\n",
    "\n",
    "# Shuffle training set\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, y_train = X_train[perm], y_train[perm]\n",
    "\n",
    "# Extract activity labels\n",
    "act_train = y_train[:, 1]\n",
    "act_val = y_val[:, 1]\n",
    "\n",
    "# Binarize\n",
    "lb = LabelBinarizer()\n",
    "Y_train = lb.fit_transform(act_train)\n",
    "Y_val = lb.transform(act_val)\n",
    "print(\"Label Mapping:\", dict(zip(lb.classes_, lb.transform(lb.classes_))))\n",
    "\n",
    "# Class weights\n",
    "cw = compute_class_weight(\"balanced\", classes=lb.classes_, y=act_train)\n",
    "class_weight_dict = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "model = build_finetuned_model(num_classes=len(lb.classes_))\n",
    "\n",
    "steps_per_epoch = int(np.ceil(len(Y_train) / BATCH_SIZE))\n",
    "validation_steps = int(np.ceil(len(Y_val) / BATCH_SIZE))\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau('val_loss', factor=0.1, patience=3, min_lr=1e-6, verbose=1),\n",
    "    EarlyStopping('val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    data_generator(X_train, Y_train, BATCH_SIZE, shuffle=True),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=data_generator(X_val, Y_val, BATCH_SIZE, shuffle=False),\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_save_path = OUTPUT_MODEL_ROOT / HAND / str(SR)\n",
    "model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "model.save(model_save_path / \"Audio_Scratch.h5\")\n",
    "\n",
    "X_test, y_test = load_combined(TEST_IDS)\n",
    "act_test = y_test[:, 1]\n",
    "Y_test = lb.transform(act_test)\n",
    "\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "y_pred = lb.classes_[np.argmax(preds, axis=1)]\n",
    "\n",
    "ba = balanced_accuracy_score(act_test, y_pred) * 100\n",
    "f1 = f1_score(act_test, y_pred, average='weighted') * 100\n",
    "\n",
    "with open(METRICS_ROOT / \"test_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Balanced Accuracy: {ba:.2f}%\\nF1 Score: {f1:.2f}%\\n\")\n",
    "\n",
    "print(f\"Test BA: {ba:.2f}%  F1: {f1:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
