{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Audio Training Pipeline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT / \"..\" / \"..\" / \"..\" / \"HCAR\"))\n",
    "\n",
    "# GPU configuration\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Seeds for reproducibility\n",
    "SEED = 20\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "HAND = 'Right'\n",
    "SUB_SR = 16000\n",
    "IMU_SR = 50\n",
    "WINDOW_LEN_IMU = 2 * IMU_SR      # 2 seconds\n",
    "HOP_LEN_IMU    = int(0.2 * IMU_SR)  # 0.2s stride\n",
    "\n",
    "# Model input shape\n",
    "IMU_INPUT_SHAPE = (100, 9)\n",
    "AUDIO_INPUT_SHAPE = (96, 64, 1)\n",
    "\n",
    "# Model version\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "# Participants\n",
    "TRAIN_PIDS = [100]\n",
    "VALID_PIDS = [101]\n",
    "TEST_PIDS = [102, 103]\n",
    "\n",
    "# Paths\n",
    "BASE_PATH = Path(\"../../\")\n",
    "DATA_PATH = BASE_PATH / \"Data/Train_Data/3_MMExamples\"\n",
    "MODEL_SAVE_PATH = BASE_PATH / f\"Models/tensorflow_model/Audio/Audio_ver{MODEL_VERSION}/{HAND}\"\n",
    "ACC_SAVE_PATH = BASE_PATH / f\"../../Results/Train_Result/Model_Accuracy/Audio/Audio_ver{MODEL_VERSION}/{HAND}\"\n",
    "PRED_SAVE_PATH = BASE_PATH / f\"../../Results/Train_Result/Model_Preds/Audio/Audio_ver{MODEL_VERSION}/{HAND}\"\n",
    "NORM_PATH = BASE_PATH / f\"Normalization_params/normalization_params_{HAND}_ver{MODEL_VERSION}.pkl\"\n",
    "\n",
    "REF_MODEL_PATH = BASE_PATH / \"Models/Reference_Model\"\n",
    "\n",
    "MODEL_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "ACC_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "PRED_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Utility functions\n",
    "def load_audio_examples(pid_set):\n",
    "    X, y = [], []\n",
    "    for pid in pid_set:\n",
    "        folder = DATA_PATH / f'{pid}' / HAND / str(SUB_SR)\n",
    "        for file in folder.iterdir():\n",
    "            pid_str, activity, trial = file.stem.split('---')\n",
    "            data = pkl.load(open(file, 'rb'))\n",
    "            X.append(data)\n",
    "            y.extend([[pid_str, activity]] * len(data))\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = pd.DataFrame(y, columns=['pid', 'activity'])\n",
    "    return X, y\n",
    "\n",
    "# Model definition\n",
    "def create_audio_model(input_shape=(96,64,1), num_classes=6):\n",
    "    inp = Input(shape=input_shape, name='Audio_input')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same')(inp)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def evaluate_and_save(model: Model, X_audio, y_labels, lb: LabelBinarizer):\n",
    "    # Perform filewise prediction, compute metrics, save results.\n",
    "    preds = model.predict(X_audio, batch_size=BATCH_SIZE)\n",
    "    df = pd.DataFrame(preds, columns=lb.classes_)\n",
    "    df['file_name'] = y_labels[:,1]\n",
    "    df['y_pred'] = df.drop(columns=['file_name']).idxmax(axis=1)\n",
    "    df['y_true'] = df['file_name']\n",
    "\n",
    "    ba = balanced_accuracy_score(df['y_true'], df['y_pred'])\n",
    "    f1 = f1_score(df['y_true'], df['y_pred'], average='weighted')\n",
    "    return df, ba, f1\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "\n",
    "    # Data loading\n",
    "    X_train, y_train_df = load_audio_examples(TRAIN_PIDS)\n",
    "    X_val, y_val_df = load_audio_examples(VALID_PIDS)\n",
    "    X_test, y_test_df = load_audio_examples(TEST_PIDS)\n",
    "\n",
    "    # Label encoding\n",
    "    lb = LabelBinarizer()\n",
    "    y_train = lb.fit_transform(y_train_df['activity'])\n",
    "    y_val = lb.transform(y_val_df['activity'])\n",
    "    y_test = lb.transform(y_test_df['activity'])\n",
    "\n",
    "    # Class weights\n",
    "    train_weights = class_weight.compute_class_weight('balanced', classes=lb.classes_, y=y_train_df['activity'])\n",
    "    class_weights = dict(enumerate(train_weights))\n",
    "\n",
    "    # Prepare model\n",
    "    audio_model = create_audio_model()\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    # Training\n",
    "    epochs, batch_size = 30, 32\n",
    "    audio_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    audio_model.save(MODEL_SAVE_PATH / HAND / str(SUB_SR) / 'audio_model.h5')\n",
    "\n",
    "    # Evaluate\n",
    "    results_df, ba, f1 = evaluate_and_save(audio_model, X_test, y_test, lb)\n",
    "    results_df.to_csv(PRED_SAVE_PATH / f'{HAND}.csv', index=False)\n",
    "\n",
    "    with open(ACC_SAVE_PATH / 'Audio_Scratch.txt', 'w') as f:\n",
    "        f.write(f'Balanced Accuracy: {ba}\\nF1 Score: {f1}\\n')\n",
    "\n",
    "    # Cleanup\n",
    "    del audio_model, X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    gc.collect()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
