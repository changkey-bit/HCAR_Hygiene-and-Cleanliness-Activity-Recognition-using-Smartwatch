{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "SEED        = 4\n",
    "MODEL_VER   = 5\n",
    "SR          = 16000\n",
    "PARTICIPANT = \"16\"\n",
    "\n",
    "BASE_DATA   = Path(\"../../Data/Pilot_Data/3. PreprocessDataset_for_Audio\")\n",
    "TFLITE_PATH = Path(f\"../../Models/tflite_model/Audio/Audio_ver{MODEL_VER}.tflite\")\n",
    "LABEL_BIN   = Path(f\"../../LabelBinarizer/Audio/Audio_Label_binarizer_ver{MODEL_VER}.pkl\")\n",
    "PRED_DIR    = Path(f\"../../Model_Preds/Audio/{PARTICIPANT}\")\n",
    "ACC_FILE    = Path(f\"../../Model_Accuracy/Audio/{PARTICIPANT}_accuracy.txt\")\n",
    "CM_DIR      = Path(f\"../../Confusion_Matrix/{PARTICIPANT}\")\n",
    "\n",
    "CLASS_ORDER = ['Tooth_brushing', 'Washing_hands', 'Wiping', 'Vacuum_Cleaner', 'Other']\n",
    "\n",
    "# Reproducibility\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Ensure output directories exist\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_interpreter(model_path: Path) -> tf.lite.Interpreter:\n",
    "    \"\"\"Load and return a TFLite interpreter.\"\"\"\n",
    "    interp = tf.lite.Interpreter(model_path=str(model_path))\n",
    "    interp.allocate_tensors()\n",
    "    return interp\n",
    "\n",
    "interpreter = make_interpreter(TFLITE_PATH)\n",
    "input_details  = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "audio_idx      = input_details[0]['index']\n",
    "output_idx     = output_details[0]['index']\n",
    "\n",
    "def infer_participant(pid: str, lb: LabelBinarizer) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run TFLite inference on each audio frame for a single participant.\n",
    "    Returns a DataFrame of per-frame softmax scores plus true/pred labels.\n",
    "    \"\"\"\n",
    "    pkl_path = BASE_DATA / pid / f\"{pid}_preprocessing_for_audio.pkl\"\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    X = data[\"Audio\"].astype(np.float32)\n",
    "    y = np.array(data[\"Activity\"], dtype=object)\n",
    "\n",
    "    softmaxes = []\n",
    "    for frame in tqdm(X, desc=f\"Infer {pid}\"):\n",
    "        inp = frame[None, ..., None]  # add batch and channel dims\n",
    "        interpreter.set_tensor(audio_idx, inp)\n",
    "        interpreter.invoke()\n",
    "        softmaxes.append(interpreter.get_tensor(output_idx)[0])\n",
    "\n",
    "    df = pd.DataFrame(softmaxes, columns=lb.classes_)\n",
    "    df[\"y_true\"] = y\n",
    "    df[\"y_pred\"] = df.drop(columns=[\"y_true\"]).idxmax(axis=1)\n",
    "    return df\n",
    "\n",
    "with open(LABEL_BIN, \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "print(\"Label mapping:\", dict(zip(lb.classes_, lb.transform(lb.classes_))))\n",
    "\n",
    "df_preds = infer_participant(PARTICIPANT, lb)\n",
    "df_preds.to_csv(PRED_DIR / f\"{PARTICIPANT}_ver{MODEL_VER}.csv\", index=False)\n",
    "\n",
    "ba = balanced_accuracy_score(df_preds[\"y_true\"], df_preds[\"y_pred\"])\n",
    "f1 = f1_score(df_preds[\"y_true\"], df_preds[\"y_pred\"], average=\"weighted\")\n",
    "print(f\"Balanced Accuracy: {ba:.4f}\")\n",
    "print(f\"F1 Score:           {f1:.4f}\")\n",
    "\n",
    "with open(ACC_FILE, \"w\") as f:\n",
    "    f.write(f\"Balanced Accuracy: {ba:.4f}\\nF1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "cm = confusion_matrix(df_preds[\"y_true\"], df_preds[\"y_pred\"], labels=CLASS_ORDER)\n",
    "cm_pct = 100 * cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "cm_pct = np.nan_to_num(cm_pct)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm_pct, cmap=\"Greens\", vmin=0, vmax=100)\n",
    "ax.set_xticks(range(len(CLASS_ORDER)))\n",
    "ax.set_xticklabels(CLASS_ORDER, rotation=45, ha=\"right\")\n",
    "ax.set_yticks(range(len(CLASS_ORDER)))\n",
    "ax.set_yticklabels(CLASS_ORDER)\n",
    "for i in range(len(CLASS_ORDER)):\n",
    "    for j in range(len(CLASS_ORDER)):\n",
    "        color = \"white\" if cm_pct[i, j] > 50 else \"black\"\n",
    "        ax.text(j, i, f\"{cm_pct[i, j]:.1f}%\", ha=\"center\", va=\"center\", color=color)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_title(\"Confusion Matrix (%)\")\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_DIR / f\"{PARTICIPANT}_confusion.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
