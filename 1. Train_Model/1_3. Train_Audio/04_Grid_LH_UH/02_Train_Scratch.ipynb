{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "SEED           = 4\n",
    "MODEL_VERSION  = 36\n",
    "TRAIN_IDS      = [10, 100, 101, 102, 103]\n",
    "VALID_IDS      = [104]\n",
    "TEST_IDS       = [3, 4]\n",
    "LOWER_EDGES    = [100, 500]\n",
    "UPPER_EDGES    = [6000, 8000, 10000]\n",
    "BATCH_SIZE     = 32\n",
    "EPOCHS         = 30\n",
    "SR             = 16000\n",
    "HAND           = \"Right\"\n",
    "CLASS_NAMES    = ['Tooth_brushing','Washing_hands','Shower','Wiping','Vacuum_Cleaner']\n",
    "NUM_CLASSES    = len(CLASS_NAMES)\n",
    "\n",
    "BASE_DATA      = Path(\"../../Data/Train_Data/4. AudioExamples\")\n",
    "BASE_MODEL     = Path(f\"../../Models/tensorflow_model/Audio/Audio_ver{MODEL_VERSION}\")\n",
    "BASE_RESULTS   = Path(f\"../../Result/Train_Result/Model_Preds/Audio/Audio_ver{MODEL_VERSION}\")\n",
    "REF_MODEL_PATH = Path(\"../../Models/Reference_Model/example_model.hdf5\")\n",
    "\n",
    "# Seeds\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]  = \"0\"\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in (BASE_MODEL, BASE_RESULTS):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Data Loading\n",
    "\n",
    "def load_audio_examples(pid_list, lower, upper):\n",
    "    \"\"\"\n",
    "    Load and concatenate VGGish log-mel examples for given participants\n",
    "    and mel-band edges.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for pid in pid_list:\n",
    "        folder = BASE_DATA / f\"LEH{lower}_UEH{upper}\" / str(pid) / HAND / str(SR)\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        for pkl_file in tqdm(list(folder.iterdir()), desc=f\"PID {pid}\"):\n",
    "            _, activity, _ = pkl_file.stem.split(\"---\")\n",
    "            with open(pkl_file, \"rb\") as f:\n",
    "                examples = pickle.load(f)\n",
    "            X.append(examples)\n",
    "            y += [activity] * len(examples)\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    return X, np.array(y)\n",
    "\n",
    "# Model Creation\n",
    "def warm_start_model(num_classes):\n",
    "    \"\"\"\n",
    "    Load a reference model, replace its top layer for `num_classes` outputs,\n",
    "    and compile it.\n",
    "    \"\"\"\n",
    "    base = tf.keras.models.load_model(REF_MODEL_PATH)\n",
    "    x    = base.layers[-2].output\n",
    "    out  = Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "    model = Model(base.input, out)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Training Loop\n",
    "def train_and_save(lower, upper):\n",
    "    print(f\"\\n=== Training LEH={lower}, UEH={upper} ===\")\n",
    "\n",
    "    # Load datasets\n",
    "    X_train, y_train = load_audio_examples(TRAIN_IDS, lower, upper)\n",
    "    X_val,   y_val   = load_audio_examples(VALID_IDS, lower, upper)\n",
    "\n",
    "    # Shuffle training set\n",
    "    idx = np.random.permutation(len(X_train))\n",
    "    X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "    # One-hot encode\n",
    "    lb        = LabelBinarizer().fit(CLASS_NAMES)\n",
    "    Y_train   = lb.transform(y_train)\n",
    "    Y_val     = lb.transform(y_val)\n",
    "\n",
    "    # Compute class weights\n",
    "    weights   = class_weight.compute_class_weight(\n",
    "        \"balanced\", classes=CLASS_NAMES, y=y_train\n",
    "    )\n",
    "    cw_dict   = {i: w for i, w in enumerate(weights)}\n",
    "\n",
    "    # Prepare model\n",
    "    model = warm_start_model(len(CLASS_NAMES))\n",
    "\n",
    "    # Callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(\"val_loss\", factor=0.1, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stp = EarlyStopping(\"val_loss\", patience=5, verbose=1)\n",
    "\n",
    "    # Fit\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_weight=cw_dict,\n",
    "        callbacks=[reduce_lr, early_stp],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    out_dir = BASE_MODEL / HAND / str(SR)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.save(out_dir / f\"LEH{lower}_UEH{upper}_model.h5\")\n",
    "\n",
    "# Execute training for all parameter combinations\n",
    "for low in LOWER_EDGES:\n",
    "    for high in UPPER_EDGES:\n",
    "        train_and_save(low, high)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
