{
 "cells": [
  {
   "cell_type": "code",
   "id": "57a1c26a",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration\n",
    "MODEL_VERSION = 1\n",
    "HAND = 'Right'\n",
    "SUB_SR = 16000\n",
    "TRAIN_PIDS = [100]\n",
    "VALID_PIDS = [101]\n",
    "TEST_PIDS = [102, 103]\n",
    "CLASS_NAMES = ['Shower', 'Tooth_brushing', 'Washing_hands', 'Vacuum_Cleaner', 'Wiping', 'Other']\n",
    "CLASS_LABELS = [\"S\", \"TB\", \"WH\", \"VC\", \"W\", 'O']\n",
    "BATCH_SIZE = 32\n",
    "IMU_SR = 50\n",
    "STRIDE = 0.2\n",
    "WIN_LEN_IMU = 2 * IMU_SR\n",
    "HOP_LEN_IMU = int(IMU_SR * STRIDE)\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"../../\")\n",
    "DATA_DIR = BASE_DIR / \"Data/Train_Data/3_MMExamples\"\n",
    "MODEL_PATH = BASE_DIR / f\"Models/tensorflow_model/Multimodal/MultiModal_ver{MODEL_VERSION}/{HAND}/MM_Scratch.h5\"\n",
    "NORM_PARAM_PATH = BASE_DIR / f\"Normalization_params/Normalization_params_pickle/normalization_params_{HAND}_ver{MODEL_VERSION}.pkl\"\n",
    "LB_PATH = BASE_DIR / f\"LabelBinarizer/Label_binarizer_6_classes.pkl\"\n",
    "\n",
    "# GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Utility Functions\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pkl.load(f)\n",
    "\n",
    "def frame(data, win_len, hop_len):\n",
    "    \"\"\"Create overlapping frames from time-series data.\"\"\"\n",
    "    if data.shape[0] < win_len:\n",
    "        pad_len = win_len - data.shape[0]\n",
    "        data = np.concatenate([data, np.zeros((pad_len,) + data.shape[1:])], axis=0)\n",
    "    num_samples = data.shape[0]\n",
    "    num_frames = 1 + (num_samples - win_len) // hop_len\n",
    "    shape = (num_frames, win_len) + data.shape[1:]\n",
    "    strides = (data.strides[0] * hop_len,) + data.strides\n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "def get_normalization_params(pids):\n",
    "    imu_all = []\n",
    "    for pid in pids:\n",
    "        data_dir = DATA_DIR / f\"{pid}\" / HAND / f\"{SUB_SR}\"\n",
    "        for file_path in tqdm(data_dir.iterdir()):\n",
    "            try:\n",
    "                data = load_pickle(file_path)[\"IMU\"]\n",
    "                if data.shape[0] == 0: continue\n",
    "                imu_all.append(data)\n",
    "            except:\n",
    "                continue\n",
    "    imu_concat = np.concatenate(imu_all, axis=0)\n",
    "    imu_flat = imu_concat.reshape(-1, imu_concat.shape[-1])\n",
    "    return {\n",
    "        \"max\": np.percentile(imu_flat, 80, axis=0),\n",
    "        \"min\": np.percentile(imu_flat, 20, axis=0),\n",
    "        \"mean\": np.mean(imu_flat, axis=0),\n",
    "        \"std\": np.std(imu_flat, axis=0)\n",
    "    }\n",
    "\n",
    "def normalize_data(x, norm):\n",
    "    \"\"\"Min-max normalize to [-1, 1], then standardize.\"\"\"\n",
    "    x_norm = 1 + (x - norm[\"max\"]) * 2 / (norm[\"max\"] - norm[\"min\"])\n",
    "    x_std = (x_norm - norm[\"mean\"]) / norm[\"std\"]\n",
    "    return x_std\n",
    "\n",
    "def load_data(pids, norm_params):\n",
    "    X_imu, X_audio, y_all = [], [], []\n",
    "    for pid in pids:\n",
    "        data_dir = DATA_DIR / f\"{pid}\" / HAND / f\"{SUB_SR}\"\n",
    "        for file_path in tqdm(data_dir.iterdir()):\n",
    "            name = file_path.stem\n",
    "            _, activity, trial = name.split(\"---\")\n",
    "            if activity not in CLASS_NAMES:\n",
    "                continue\n",
    "            data = load_pickle(file_path)\n",
    "            imu, audio = data[\"IMU\"], data[\"audio\"]\n",
    "            if imu.shape[0] == 0: continue\n",
    "            imu = normalize_data(imu, norm_params)\n",
    "            X_imu.append(imu)\n",
    "            X_audio.append(audio)\n",
    "            y_all.extend([[pid, activity, trial]] * imu.shape[0])\n",
    "    return (\n",
    "        np.concatenate(X_imu, axis=0),\n",
    "        np.concatenate(X_audio, axis=0),\n",
    "        np.array(y_all)\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, X_imu, X_audio, y_true, lb):\n",
    "    y_pred_prob = model.predict([X_imu, X_audio], batch_size=BATCH_SIZE)\n",
    "    y_pred = lb.inverse_transform(y_pred_prob)\n",
    "\n",
    "    ba = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"Balanced Accuracy: {ba:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "    return y_pred\n",
    "\n",
    "def plot_confusion(y_true, y_pred, labels, label_short):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_pct = np.nan_to_num(cm / cm.sum(axis=1, keepdims=True) * 100)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm_pct, cmap='Blues', vmin=0, vmax=100)\n",
    "\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(label_short, fontsize=16)\n",
    "    ax.set_yticklabels(label_short, fontsize=16)\n",
    "    ax.tick_params(axis='x', pad=10)\n",
    "    ax.tick_params(axis='y', pad=10)\n",
    "\n",
    "    thresh = cm_pct.max() / 2\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(j, i, f\"{cm_pct[i, j]:.2f}\", ha='center', va='center',\n",
    "                    color='white' if cm_pct[i, j] > thresh else 'black', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load Resources\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "norm_params = load_pickle(NORM_PARAM_PATH)\n",
    "lb = load_pickle(LB_PATH)\n",
    "\n",
    "# Run Inference\n",
    "X_imu_test, X_audio_test, y_array = load_data(TEST_PIDS, norm_params)\n",
    "\n",
    "# Copying an input array to a contiguous memory array\n",
    "X_imu_test   = np.ascontiguousarray(X_imu_test,   dtype=np.float32)\n",
    "X_audio_test = np.ascontiguousarray(X_audio_test, dtype=np.float32)\n",
    "\n",
    "y_true = y_array[:, 1]\n",
    "y_pred = evaluate_model(model, X_imu_test, X_audio_test, y_true, lb)\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion(y_true, y_pred, labels=CLASS_NAMES, label_short=CLASS_LABELS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5189e47e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
