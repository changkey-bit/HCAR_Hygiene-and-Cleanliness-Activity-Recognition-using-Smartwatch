{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TFLite & TensorFlow Model Evaluation Pipeline\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('../../Data/Experiment_Data/2_PreprocessDataset')\n",
    "MODEL_DIR = Path('../../Models/TFlite_model/Multimodal')\n",
    "OUTPUT_ACC_DIR = Path('../../Result/Experiment_Result/Model_Accuracy')\n",
    "OUTPUT_PRED_DIR = Path('../..//Result/Experiment_Result/Model_Preds/Multimodal')\n",
    "OUTPUT_CM_DIR = Path('../..//Result/Experiment_Result/Confusion_Matrix/Multimodal/NoTimeVoting')\n",
    "\n",
    "# Environment\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Seeds\n",
    "SEED = 4\n",
    "random = np.random.RandomState(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Threads\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "\n",
    "# Model parameters\n",
    "MODEL_VERSION = 1\n",
    "TFLITE_MODEL = MODEL_DIR / f'quan_multimodal_cnn_ver{MODEL_VERSION}.tflite'\n",
    "\n",
    "# Load normalization params & label binarizer\n",
    "with open(f'../../Normalization_params/Normalization_params_pickle/normalization_params_Right_ver{MODEL_VERSION}.pkl','rb') as f:\n",
    "    norm_params = pkl.load(f)\n",
    "with open('../../LabelBinarizer/Label_binarizer_6_classes.pkl','rb') as f:\n",
    "    lb = pkl.load(f)\n",
    "    print('Label mapping:', dict(zip(lb.classes_, lb.transform(lb.classes_))))\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['Shower','Tooth_brushing','Washing_hands','Wiping','Vacuum_Cleaner','Other']\n",
    "\n",
    "# Utility: batch TFLite inference\n",
    "def tflite_batch_predict(model_path: Path, pid: str, batch_size: int = 128) -> pd.DataFrame:\n",
    "    # Load TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(model_path), num_threads=4)\n",
    "    interp_inputs = interpreter.get_input_details()\n",
    "    interp_output = interpreter.get_output_details()[0]\n",
    "\n",
    "    # Resize inputs for batching\n",
    "    imu_shape = list(interp_inputs[0]['shape'])\n",
    "    audio_shape = list(interp_inputs[1]['shape'])\n",
    "    interpreter.resize_tensor_input(interp_inputs[0]['index'], [batch_size]+imu_shape[1:])\n",
    "    interpreter.resize_tensor_input(interp_inputs[1]['index'], [batch_size]+audio_shape[1:])\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Data load\n",
    "    pkl_path = DATA_DIR / pid / f'{pid}_preprocessing.pkl'\n",
    "    data = pkl.load(open(pkl_path,'rb'))\n",
    "    imu = data['IMU'].astype(np.float32)\n",
    "    audio = data['Audio'].astype(np.float32)\n",
    "    y_true = np.array(data['Activity'])\n",
    "\n",
    "    # Normalize IMU\n",
    "    for key in ['max','min','mean','std']:\n",
    "        norm_params[key] = norm_params[key].astype(np.float32)\n",
    "    pm,pn,mu,sd = [norm_params[k].reshape(1,1,-1) for k in ('max','min','mean','std')]\n",
    "    imu = 1 + (imu - pm)*2/(pm - pn)\n",
    "    imu = (imu - mu)/sd\n",
    "\n",
    "    # Prepare audio\n",
    "    audio = np.expand_dims(audio, -1)\n",
    "\n",
    "    # Predict in batches\n",
    "    preds = []\n",
    "    n = imu.shape[0]\n",
    "    for i in tqdm(range(0,n,batch_size)):\n",
    "        end = min(i+batch_size, n)\n",
    "        b_imu = imu[i:end]\n",
    "        b_audio = audio[i:end]\n",
    "        # Resize last batch if needed\n",
    "        if b_imu.shape[0] != batch_size:\n",
    "            interpreter.resize_tensor_input(interp_inputs[0]['index'], [b_imu.shape[0]]+imu_shape[1:])\n",
    "            interpreter.resize_tensor_input(interp_inputs[1]['index'], [b_audio.shape[0]]+audio_shape[1:])\n",
    "            interpreter.allocate_tensors()\n",
    "        interpreter.set_tensor(interp_inputs[0]['index'], b_imu)\n",
    "        interpreter.set_tensor(interp_inputs[1]['index'], b_audio)\n",
    "        interpreter.invoke()\n",
    "        out = interpreter.get_tensor(interp_output['index'])\n",
    "        preds.append(out)\n",
    "    preds = np.vstack(preds)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(preds, columns=lb.classes_)\n",
    "    df.insert(0, 'y_true', y_true)\n",
    "    return df\n",
    "\n",
    "# Main evaluation loop\n",
    "for pid in sorted(DIR for DIR in os.listdir(DATA_DIR) if (DATA_DIR/DIR).is_dir()):\n",
    "    print(f'Processing {pid}...')\n",
    "    # Batch predict\n",
    "    df_pred = tflite_batch_predict(TFLITE_MODEL, pid)\n",
    "    df_pred['y_pred'] = df_pred.drop(columns=['y_true']).idxmax(axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    ba = balanced_accuracy_score(df_pred['y_true'], df_pred['y_pred'])\n",
    "    f1 = f1_score(df_pred['y_true'], df_pred['y_pred'], average='weighted')\n",
    "    # Save accuracy\n",
    "    OUTPUT_ACC_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    with open(OUTPUT_ACC_DIR/f'{pid}_accuracy.txt','w') as f:\n",
    "        f.write(f'Balanced Accuracy: {ba:.4f}\\nF1 Score: {f1:.4f}\\n')\n",
    "\n",
    "    # Save predictions\n",
    "    pred_dir = OUTPUT_PRED_DIR / pid\n",
    "    pred_dir.mkdir(exist_ok=True, parents=True)\n",
    "    df_pred.to_csv(pred_dir/f'{pid}_quan_ver{MODEL_VERSION}.csv', index=False)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(df_pred['y_true'], df_pred['y_pred'], labels=CLASS_NAMES)\n",
    "    cm_pct = (cm.astype(float)/cm.sum(axis=1)[:,None])*100\n",
    "    cm_pct = np.nan_to_num(cm_pct)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    im = ax.imshow(cm_pct, cmap='Greens', vmin=0, vmax=100)\n",
    "    ax.set_xticks(range(len(CLASS_NAMES)))\n",
    "    ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "    ax.set_yticks(range(len(CLASS_NAMES)))\n",
    "    ax.set_yticklabels(CLASS_NAMES)\n",
    "    thresh = cm_pct.max()/2\n",
    "    for i in range(cm_pct.shape[0]):\n",
    "        for j in range(cm_pct.shape[1]):\n",
    "            color = 'white' if cm_pct[i,j]>thresh else 'black'\n",
    "            ax.text(j,i,f'{cm_pct[i,j]:.1f}', ha='center', va='center', color=color, weight='bold')\n",
    "    ax.set_title('Confusion Matrix without TimeVoting')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save image\n",
    "    save_cm = OUTPUT_CM_DIR / pid\n",
    "    save_cm.mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(save_cm/f'{pid}_NoTimeVoting_Confusion.png')\n",
    "    plt.close(fig)\n",
    "    gc.collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite_0505",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
