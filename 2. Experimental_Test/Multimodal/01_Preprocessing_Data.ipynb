{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T04:58:05.121102Z",
     "start_time": "2025-07-29T04:49:12.783460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from tqdm import tqdm\n",
    "from utils import vggish_input, params\n",
    "import pandas as pd\n",
    "\n",
    "# Add project directory for HCAR utils\n",
    "def add_time_zero_row(df, time_col='Time', unixtime_col='UnixTime'):\n",
    "    \"\"\"\n",
    "    Ensure a row at time zero in the DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[time_col]     = pd.to_numeric(df[time_col],     errors='coerce')\n",
    "    df[unixtime_col] = pd.to_numeric(df[unixtime_col], errors='coerce')\n",
    "\n",
    "    if (df[time_col] == 0).any():\n",
    "        return df\n",
    "\n",
    "    first = df.iloc[0].copy()\n",
    "    new = first.copy()\n",
    "    new[time_col]     = 0\n",
    "    new[unixtime_col] = first[unixtime_col] - int(first[time_col] * 1000)\n",
    "    return pd.concat([pd.DataFrame([new]), df], ignore_index=True)\n",
    "\n",
    "def frame(data, window_length, hop_length):\n",
    "    \"\"\"\n",
    "    Frame 2D array into overlapping windows.\n",
    "    \"\"\"\n",
    "    if data.shape[0] < window_length:\n",
    "        pad_n = window_length - data.shape[0]\n",
    "        data = np.vstack([data, np.zeros((pad_n, data.shape[1]))])\n",
    "    n_frames = 1 + (data.shape[0] - window_length) // hop_length\n",
    "    shape    = (n_frames, window_length, data.shape[1])\n",
    "    strides  = (hop_length * data.strides[0],) + data.strides\n",
    "    return as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "def rebuild_waveform(df):\n",
    "    \"\"\"\n",
    "    Flatten multi-column audio data to a waveform and return start time.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c.startswith('AudioData')]\n",
    "    arr  = df[cols].to_numpy(dtype=np.int16)\n",
    "    times= df['UnixTime_s'].to_numpy()\n",
    "    return arr.flatten(), times[0]\n",
    "\n",
    "def generate_mel_chunks(waveform, sr=16000, lower_edge_hertz=10,\n",
    "                         upper_edge_hertz=8000, chunk_secs=10):\n",
    "    \"\"\"\n",
    "    Generate mel spectrogram chunks from a long waveform.\n",
    "    \"\"\"\n",
    "    chunk_samples = int(chunk_secs * sr)\n",
    "    mel_chunks = []\n",
    "    for start in tqdm(range(0, len(waveform), chunk_samples)):\n",
    "        chunk = waveform[start:start + chunk_samples]\n",
    "        if chunk.size == 0:\n",
    "            break\n",
    "        mel = vggish_input.wavform_to_concat_examples(\n",
    "            chunk,\n",
    "            lower_edge_hertz=lower_edge_hertz,\n",
    "            upper_edge_hertz=upper_edge_hertz,\n",
    "            sr=sr\n",
    "        )\n",
    "        mel_chunks.append(mel)\n",
    "    return np.concatenate(mel_chunks, axis=0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DATA_PATH = Path(\"../../Data/Experiment_Data/1_RawDataset\")\n",
    "    SAVE_PATH = Path(\"../../Data/Experiment_Data/2_PreprocessDataset\")\n",
    "\n",
    "    participants = [d.name for d in DATA_PATH.iterdir() if d.is_dir()]\n",
    "    class_list = [\n",
    "        'Tooth_brushing', 'Washing_hands', 'Shower',\n",
    "        'Wiping', 'Vacuum_Cleaner', 'Other'\n",
    "    ]\n",
    "\n",
    "    for participant in participants:\n",
    "        if participant == '204':\n",
    "            continue\n",
    "        folder = DATA_PATH / participant\n",
    "\n",
    "        # Load CSVs\n",
    "        anno_df = pd.read_csv(\n",
    "            next(folder.glob('*annotation.csv')), engine='python', on_bad_lines='skip'\n",
    "        )\n",
    "        pred_df = pd.read_csv(\n",
    "            next(folder.glob('*Predicted_Activity.csv')), engine='python', on_bad_lines='skip'\n",
    "        )\n",
    "\n",
    "        # Harmonize labels\n",
    "        anno_df['Activity'] = anno_df['Activity'].str.replace(\n",
    "            'Toothbrushing', 'Tooth_brushing', regex=False)\n",
    "        pred_df['Predict']   = pred_df['Predict'].str.replace(' ', '_', regex=False)\n",
    "\n",
    "        # Insert time-zero\n",
    "        anno_df = add_time_zero_row(anno_df)\n",
    "        pred_df = add_time_zero_row(pred_df)\n",
    "\n",
    "        # Align annotation times\n",
    "        delta = pred_df.loc[pred_df.Time==0, 'UnixTime'].iloc[0] - \\\n",
    "                anno_df.loc[anno_df.Time==0, 'UnixTime'].iloc[0]\n",
    "        anno_df['UnixTime'] += delta\n",
    "\n",
    "        # Truncate and add Session Stop\n",
    "        end_unix = pred_df['UnixTime'].max()\n",
    "        anno_df = anno_df[anno_df['UnixTime'] <= end_unix]\n",
    "        last = pred_df.loc[pred_df.UnixTime.idxmax()].to_dict()\n",
    "        last.update({'Event':'Session Stop','Activity':'','Confirm':''})\n",
    "        anno_df = pd.concat([anno_df, pd.DataFrame([last])], ignore_index=True)\n",
    "\n",
    "        # Fix unmatched starts, drop bad ends\n",
    "        anno_df['Confirm'] = anno_df['Confirm'].fillna('')\n",
    "        df = anno_df.copy()\n",
    "        next_act = df['Activity'].shift(-1)\n",
    "        next_evt = df['Event'].shift(-1)\n",
    "        df = df[~((df.Event=='Start') & ~((next_act==df.Activity)&(next_evt=='End')))]\n",
    "        drop = []\n",
    "        for idx,row in df[(df.Event=='End')&(df.Confirm=='no')].iterrows():\n",
    "            starts = df[(df.Activity==row.Activity)&(df.Event=='Start')&(df.index<idx)]\n",
    "            drop += ([starts.index.max(), idx] if not starts.empty else [idx])\n",
    "        df = df.drop(drop).sort_values(['UnixTime','Time']).reset_index(drop=True)\n",
    "        anno_df = df\n",
    "\n",
    "        # Convert to seconds and save CSV\n",
    "        anno_df['UnixTime_s'] = anno_df['UnixTime'] / 1000.0\n",
    "        out = SAVE_PATH / participant\n",
    "        out.mkdir(parents=True, exist_ok=True)\n",
    "        anno_df.to_csv(out / f\"{participant}_Annotation_processed.csv\", index=False)\n",
    "        pred_df.to_csv(out / f\"{participant}_Predicted_Activity_processed.csv\", index=False)\n",
    "\n",
    "    # Process sensor/audio\n",
    "    for participant in participants:\n",
    "        if participant == '204':\n",
    "            continue\n",
    "        folder = DATA_PATH / participant\n",
    "        sensor_df = pd.read_csv(\n",
    "            next(folder.glob('*SensorData.csv')), engine='python', on_bad_lines='skip'\n",
    "        )\n",
    "        audio_df = pd.read_csv(\n",
    "            next(folder.glob('*AudioData.csv')), engine='python', on_bad_lines='skip'\n",
    "        )\n",
    "        anno_clean = pd.read_csv(\n",
    "            SAVE_PATH/participant/f\"{participant}_Annotation_processed.csv\"\n",
    "        )\n",
    "\n",
    "        # Remove noisy rows\n",
    "        exp = sensor_df.columns[:17]\n",
    "        extra = sensor_df.columns[17:]\n",
    "        bad = sensor_df[exp].isnull().any(1) | sensor_df[extra].notnull().any(1)\n",
    "        sensor_df = sensor_df[~bad].reset_index(drop=True)\n",
    "\n",
    "        # Add time-zero rows\n",
    "        sensor_df = add_time_zero_row(sensor_df)\n",
    "        audio_df  = add_time_zero_row(audio_df)\n",
    "\n",
    "        # Sync times\n",
    "        base_zero = sensor_df.loc[sensor_df.Time==0,'UnixTime'].iloc[0]\n",
    "        audio_df['UnixTime'] += base_zero - audio_df.loc[audio_df.Time==0,'UnixTime'].iloc[0]\n",
    "        anno_clean['UnixTime'] += base_zero - anno_clean.loc[anno_clean.Time==0,'UnixTime'].iloc[0]\n",
    "\n",
    "        # Truncate session\n",
    "        stop_ts = anno_clean.loc[anno_clean.Event=='Session Stop','UnixTime'].iloc[0]\n",
    "        sensor_df = sensor_df[sensor_df.UnixTime<=stop_ts].reset_index(drop=True)\n",
    "        audio_df  = audio_df[audio_df.UnixTime<=stop_ts].reset_index(drop=True)\n",
    "\n",
    "        # Convert to seconds\n",
    "        for df in (sensor_df, audio_df, anno_clean):\n",
    "            df['UnixTime_s'] = df['UnixTime']/1000.0\n",
    "\n",
    "        # Frame IMU (drop timestamp)\n",
    "        imu_arr = sensor_df[\n",
    "            ['AccX','AccY','AccZ','GyroX','GyroY','GyroZ','RotVecX','RotVecY','RotVecZ']\n",
    "        ].to_numpy()\n",
    "        iwlen  = int(2.0 * 50)\n",
    "        iwstep = int(0.2 * 50)\n",
    "        imu_frames = frame(imu_arr, iwlen, iwstep)\n",
    "        print(\"IMU frames shape:\", imu_frames.shape)\n",
    "\n",
    "        # Build intervals\n",
    "        intervals = []\n",
    "        stack = {}\n",
    "        for _,row in anno_clean.query(\"Event!='Session Start' and Event!='Session Stop'\").iterrows():\n",
    "            if row.Event=='Start':\n",
    "                stack[row.Activity] = row.UnixTime_s\n",
    "            else:\n",
    "                if row.Activity in stack:\n",
    "                    intervals.append((stack.pop(row.Activity), row.UnixTime_s, row.Activity))\n",
    "        print(\"Intervals:\", intervals)\n",
    "\n",
    "        # Audio waveform and mel\n",
    "        waveform, audio_start = rebuild_waveform(audio_df)\n",
    "        print(\"Audio start:\", audio_start)\n",
    "        audio_examples = generate_mel_chunks(\n",
    "            waveform, sr=16000, lower_edge_hertz=10,\n",
    "            upper_edge_hertz=8000, chunk_secs=3600\n",
    "        )\n",
    "        print(\"Mel shape:\", audio_examples.shape)\n",
    "\n",
    "        # Timestamp array for mel frames\n",
    "        hop = params.STFT_HOP_LENGTH_SECONDS\n",
    "        win = params.STFT_WINDOW_LENGTH_SECONDS\n",
    "        n_mels = audio_examples.shape[0]\n",
    "        audio_ts= audio_start + np.arange(n_mels)*hop + win\n",
    "\n",
    "        # Mel frames per example\n",
    "        ex_len = int(params.EXAMPLE_WINDOW_SECONDS / hop)\n",
    "\n",
    "        w_a, w_i, w_l = [], [], []\n",
    "        for frames in imu_frames:\n",
    "            # use separate time if available; using first col assumed time\n",
    "            s_t, e_t = frames[0,0], frames[-1,0]\n",
    "            s_idx = np.searchsorted(audio_ts, s_t)\n",
    "            e_idx = s_idx + ex_len\n",
    "            if e_idx > n_mels: continue\n",
    "            seg = audio_examples[s_idx:e_idx]\n",
    "            if seg.shape[0] < ex_len:\n",
    "                seg = np.vstack([seg, np.zeros((ex_len-seg.shape[0], seg.shape[1]))])\n",
    "            ov = {act:0.0 for act in class_list}\n",
    "            for st,et,act in intervals:\n",
    "                ov[act] += max(0, min(e_t,et)-max(s_t,st))\n",
    "            covered = sum(ov.values())\n",
    "            ov['Other'] += max(0, (e_t-s_t)-covered)\n",
    "            lbl = max(ov, key=ov.get)\n",
    "            w_a.append(seg)\n",
    "            w_i.append(frames)\n",
    "            w_l.append(lbl)\n",
    "\n",
    "        X_audio = np.stack(w_a)\n",
    "        X_imu   = np.stack([f[:, :9] for f in w_i])\n",
    "        Y_lab   = np.array(w_l)\n",
    "        print(\"Final shapes → audio:\", X_audio.shape,\n",
    "              \"imu:\", X_imu.shape, \"labels:\", Y_lab.shape)\n",
    "\n",
    "        # Save to pickle\n",
    "        out = SAVE_PATH / participant\n",
    "        out.mkdir(parents=True, exist_ok=True)\n",
    "        with open(out / f\"{participant}_preprocessing.pkl\", 'wb') as f:\n",
    "            pkl.dump({'IMU':X_imu, 'Audio':X_audio, 'Activity':Y_lab}, f, protocol=4)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU frames shape: (137563, 100, 9)\n",
      "Intervals: [(1746692221.826, 1746692293.555, 'Washing_hands'), (1746692321.585, 1746692541.304, 'Tooth_brushing'), (1746692985.85, 1746693055.83, 'Wiping'), (1746693078.087, 1746693143.191, 'Wiping'), (1746693203.624, 1746693327.819, 'Vacuum_Cleaner'), (1746693368.225, 1746693508.475, 'Vacuum_Cleaner'), (1746693557.003, 1746693635.213, 'Wiping'), (1746693792.988, 1746693863.497, 'Wiping'), (1746693880.754, 1746693979.834, 'Wiping'), (1746694039.7, 1746694048.231, 'Vacuum_Cleaner'), (1746696428.025, 1746696723.775, 'Vacuum_Cleaner'), (1746696882.776, 1746696921.721, 'Vacuum_Cleaner'), (1746697210.253, 1746697271.303, 'Wiping'), (1746697284.612, 1746697342.278, 'Wiping'), (1746697369.542, 1746697436.419, 'Washing_hands'), (1746699176.146, 1746699244.343, 'Wiping'), (1746699337.727, 1746699403.651, 'Wiping'), (1746699554.077, 1746699765.299, 'Tooth_brushing'), (1746699806.641, 1746699870.379, 'Washing_hands'), (1746703461.296, 1746703660.634, 'Tooth_brushing'), (1746703686.158, 1746703748.099, 'Washing_hands'), (1746703804.429, 1746703938.293, 'Shower'), (1746703976.234, 1746704038.77, 'Washing_hands'), (1746706438.081, 1746706506.477, 'Washing_hands'), (1746706575.846, 1746707111.605, 'Shower'), (1746707522.759, 1746707586.189, 'Washing_hands'), (1746708716.444, 1746708777.548, 'Washing_hands'), (1746709381.738, 1746709444.751, 'Washing_hands'), (1746709597.72, 1746709654.535, 'Washing_hands')]\n",
      "Audio start: 1746681123.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:34<00:00, 23.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel shape: (994498, 64)\n",
      "Final shapes → audio: (137563, 96, 64) imu: (137563, 100, 9) labels: (137563,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
