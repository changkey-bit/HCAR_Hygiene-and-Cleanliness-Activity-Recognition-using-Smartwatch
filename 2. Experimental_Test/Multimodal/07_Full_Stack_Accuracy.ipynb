{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hybrid RF + TFLite Inference Pipeline\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import onnxruntime as ort\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Configure threading\n",
    "TF_THREADS = 14\n",
    "tf.config.threading.set_intra_op_parallelism_threads(TF_THREADS)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(TF_THREADS)\n",
    "\n",
    "# Paths & models\n",
    "DATA_ROOT = Path('../../Participant')\n",
    "RF6_ONNX = Path('../../random_forest_6class_ver36.onnx')\n",
    "TFLITE_MODEL = Path('../../quan_multimodal_cnn_ver36.tflite')\n",
    "NORM_PATH = Path('../../normalization_params_Right_ver36.pkl')\n",
    "\n",
    "# Label encoders\n",
    "ENC6 = LabelEncoder().fit([\n",
    "    'Other','Shower','Tooth_brushing',\n",
    "    'Washing_hands','Wiping','Vacuum_Cleaner'\n",
    "])\n",
    "ENC2 = LabelEncoder().fit(['Other','Event'])\n",
    "\n",
    "# Load ONNX sessions\n",
    "ses6 = ort.InferenceSession(str(RF6_ONNX))\n",
    "in6 = ses6.get_inputs()[0].name; out6 = ses6.get_outputs()[0].name\n",
    "\n",
    "# Load TFLite interpreter\n",
    "interp = tf.lite.Interpreter(model_path=str(TFLITE_MODEL), num_threads=4)\n",
    "interp.allocate_tensors()\n",
    "inputs = interp.get_input_details(); outputs = interp.get_output_details()\n",
    "idx_imu = inputs[0]['index']; idx_audio = inputs[1]['index']; idx_out = outputs[0]['index']\n",
    "\n",
    "# Load normalization\n",
    "norm = pickle.load(open(NORM_PATH,'rb'))\n",
    "pm = norm['max'].reshape(1,1,-1).astype(np.float32)\n",
    "pn = norm['min'].reshape(1,1,-1).astype(np.float32)\n",
    "mu = norm['mean'].reshape(1,1,-1).astype(np.float32)\n",
    "sd = norm['std'].reshape(1,1,-1).astype(np.float32)\n",
    "\n",
    "# Feature extraction for RF\n",
    "def extract_stats(window: np.ndarray) -> np.ndarray:\n",
    "    feats = []\n",
    "    for col in range(window.shape[1]):\n",
    "        v = window[:,col]\n",
    "        feats += [v.mean(), v.std(), v.max(), v.min(),\n",
    "                  np.median(v), v.var(), skew(v), kurtosis(v)]\n",
    "    return np.array(feats, dtype=np.float32).reshape(1,-1)\n",
    "\n",
    "# Single-sample inference\n",
    "def infer_sample(imu_win: np.ndarray, audio_win: np.ndarray) -> str:\n",
    "    # RF decision\n",
    "    f = extract_stats(imu_win)\n",
    "    if rf6:= ses6.run([out6], {in6: f})[0][0][0] != 0:\n",
    "        rf_lbl = ENC6.inverse_transform([int(rf6)])[0]\n",
    "        is_other = False\n",
    "    else:\n",
    "        rf_lbl = 'Other'; is_other = True\n",
    "    # if other, skip TFLite\n",
    "    if is_other:\n",
    "        return 'Other'\n",
    "    # normalize imu\n",
    "    imu_n = ((1 + (imu_win - pm)*2/(pm-pn)) - mu)/sd\n",
    "    imu_n = imu_n.astype(np.float32)[None,...]\n",
    "    audio_n = audio_win.astype(np.float32)[None,...]\n",
    "    # resize\n",
    "    interp.resize_tensor_input(idx_imu, imu_n.shape)\n",
    "    interp.resize_tensor_input(idx_audio, audio_n.shape)\n",
    "    interp.allocate_tensors()\n",
    "    interp.set_tensor(idx_imu, imu_n)\n",
    "    interp.set_tensor(idx_audio, audio_n)\n",
    "    interp.invoke()\n",
    "    out = interp.get_tensor(idx_out)\n",
    "    t_idx = int(np.argmax(out, axis=1)[0])\n",
    "    return ENC6.inverse_transform([t_idx])[0]\n",
    "\n",
    "# Batch over dataset\n",
    "all_true, all_pred = [], []\n",
    "for pid_dir in sorted(DATA_ROOT.iterdir()):\n",
    "    if not pid_dir.is_dir(): continue\n",
    "    pid = pid_dir.name\n",
    "    data = pickle.load(open(pid_dir/f'{pid}_preprocessing.pkl','rb'))\n",
    "    IMU = data['IMU']; Audio = data['Audio']\n",
    "    if Audio.ndim==3: Audio = Audio[...,None]\n",
    "    for imu_w, aud_w, true_lbl in zip(IMU, Audio, data['Activity']):\n",
    "        pred_lbl = infer_sample(imu_w, aud_w)\n",
    "        all_true.append(true_lbl); all_pred.append(pred_lbl)\n",
    "\n",
    "# Evaluate\n",
    "labels = list(ENC6.classes_)\n",
    "ba = balanced_accuracy_score(all_true, all_pred)\n",
    "f1 = f1_score(all_true, all_pred, average='weighted')\n",
    "print(f'Overall BA: {ba:.4f}, F1: {f1:.4f}')\n",
    "\n",
    "# Confusion\n",
    "cm = confusion_matrix(all_true, all_pred, labels=labels)\n",
    "cm_pct = cm.astype(float)/cm.sum(axis=1)[:,None]*100\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "im = ax.imshow(cm_pct, cmap='Blues', vmin=0, vmax=100)\n",
    "for i,j in itertools.product(range(len(labels)), repeat=2):\n",
    "    color='white' if cm_pct[i,j]>50 else 'black'\n",
    "    ax.text(j,i,f'{cm_pct[i,j]:.1f}%', ha='center', va='center', color=color)\n",
    "ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Pred'); ax.set_ylabel('True')\n",
    "plt.title('Confusion Matrix (%)'); plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "id": "1785c706cd75dec2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
