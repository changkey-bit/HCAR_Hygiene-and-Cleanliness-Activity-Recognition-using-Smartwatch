{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Audio-Only Model Evaluation Pipeline\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR      = PROJECT_ROOT / '../Data/Experiment_Data/2. PreprocessDataset'\n",
    "TF_MODEL_PATH = PROJECT_ROOT / '../Models/tensorflow_model/Audio/Audio_new_ver36/Right/16000/Audio_Scratch.h5'\n",
    "OUTPUT_ACC    = PROJECT_ROOT / '../Result/Experiment_Result/Model_Accuracy'\n",
    "OUTPUT_PRED   = PROJECT_ROOT / '../Result/Experiment_Result/Model_Preds/Audio'\n",
    "OUTPUT_CM     = PROJECT_ROOT / '../Result/Experiment_Result/Confusion_Matrix'\n",
    "LB_PATH       = PROJECT_ROOT / '../LabelBinarizer/Multimodal/Label_binarizer_6_classes.pkl'\n",
    "\n",
    "# Load label binarizer and classes\n",
    "def load_lb():\n",
    "    return pickle.load(open(LB_PATH,'rb'))\n",
    "\n",
    "# Prediction function for TF-Keras audio model\n",
    "def predict_audio_kfold(tf_model, pid: str, lb, batch_size: int = 256) -> pd.DataFrame:\n",
    "    # Load data\n",
    "    pkl_path = DATA_DIR / pid / f'{pid}_preprocessing_1hour.pkl'\n",
    "    data = pickle.load(open(pkl_path,'rb'))\n",
    "    audio = data['Audio'].astype(np.float32)[...,None]\n",
    "    y_true = np.array(data['Activity'])\n",
    "\n",
    "    # Predict\n",
    "    preds = tf_model.predict(audio, batch_size=batch_size)\n",
    "    df = pd.DataFrame(preds, columns=lb.classes_)\n",
    "    df['y_true'] = y_true\n",
    "    df['y_pred'] = df.drop(columns=['y_true']).idxmax(axis=1)\n",
    "    return df\n",
    "\n",
    "# Evaluation & saving\n",
    "if __name__ == '__main__':\n",
    "    lb = load_lb()\n",
    "    classes = lb.classes_\n",
    "    OUTPUT_ACC.mkdir(parents=True, exist_ok=True)\n",
    "    OUTPUT_PRED.mkdir(parents=True, exist_ok=True)\n",
    "    OUTPUT_CM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load model\n",
    "    tf_model = tf.keras.models.load_model(str(TF_MODEL_PATH))\n",
    "\n",
    "    # Loop participants\n",
    "    for pid in sorted([d.name for d in DATA_DIR.iterdir() if d.is_dir()]):\n",
    "        print(f\"Evaluating audio model for {pid}\")\n",
    "\n",
    "        df_res = predict_audio_kfold(tf_model, pid, lb)\n",
    "\n",
    "        # Metrics\n",
    "        ba = balanced_accuracy_score(df_res['y_true'], df_res['y_pred'])\n",
    "        f1 = f1_score(df_res['y_true'], df_res['y_pred'], average='weighted')\n",
    "\n",
    "        # Save predictions and metrics\n",
    "        out_dir = OUTPUT_PRED / pid\n",
    "        out_dir.mkdir(exist_ok=True)\n",
    "        df_res.to_csv(out_dir / f'{pid}_audio_tf.csv', index=False)\n",
    "        with open(OUTPUT_ACC / f'{pid}_audio_tf.txt','w') as f:\n",
    "            f.write(f'Balanced Accuracy: {ba:.4f}\\nF1 Score: {f1:.4f}')\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(df_res['y_true'], df_res['y_pred'], labels=classes)\n",
    "        cm_pct = cm.astype(float)/cm.sum(axis=1)[:,None]*100\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "        im = ax.imshow(cm_pct, cmap='Greens', vmin=0, vmax=100)\n",
    "        ticks = range(len(classes))\n",
    "        ax.set_xticks(ticks); ax.set_xticklabels(classes, rotation=45)\n",
    "        ax.set_yticks(ticks); ax.set_yticklabels(classes)\n",
    "        thresh = cm_pct.max()/2\n",
    "        for i in ticks:\n",
    "            for j in ticks:\n",
    "                col = 'white' if cm_pct[i,j]>thresh else 'black'\n",
    "                ax.text(j,i,f'{cm_pct[i,j]:.1f}', ha='center', color=col)\n",
    "        plt.tight_layout()\n",
    "        cm_dir = OUTPUT_CM / pid / 'Audio'\n",
    "        cm_dir.mkdir(exist_ok=True, parents=True)\n",
    "        fig.savefig(cm_dir / f'{pid}_audio_cm.png')\n",
    "        plt.close(fig)\n",
    "        print(f\"{pid}: BA={ba:.3f}, F1={f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_ver3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
